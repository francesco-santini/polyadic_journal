\documentclass{llncs}
\usepackage{mathptmx}

\usepackage{amsmath,amssymb,amsxtra,amsfonts,cancel}
\usepackage{graphicx,paralist}
\usepackage{url}
\usepackage{tikz-cd}
\usetikzlibrary{trees, arrows}
\usepackage{xspace}
%\usepackage{hyperref}
\usepackage{setspace}
\usepackage{tikz}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
\usepackage{textcomp}
\usepackage{soul}
\usepackage{listings}
\usepackage{mathtools}

\usepackage{todonotes}
% To disable notes without deleting them
%\usepackage[disable]{todonotes}

%\floatstyle{plain}
%\newfloat{myalgo}{tbhp}{mya}

\newenvironment{Algorithm}[2][tbh]%
{\begin{myalgo}[#1]
		\centering
		\begin{minipage}{#2}
			\begin{algorithm}[H]}%
			{\end{algorithm}
		\end{minipage}
	\end{myalgo}}
% to cut ------------------------------------------------------
%\usepackage{paralist}
%\usepackage[small]{caption}
%\usepackage{textcomp}
%\usepackage{times}
%\addtolength{\floatsep}{-5mm} \addtolength{\textfloatsep}{-5mm}
% -------------------------------------------------------------

\newtheorem{define}[theorem]{Definition}

\newtheorem{exa}[theorem]{Example}
\def\smallromani{\renewcommand{\theenumi}{\roman{enumi}}
        \renewcommand{\labelenumi}{(\theenumi)}}

%\def\bigodiv{{ \mathbf{\bigodot \hspace{-11pt} \boxempty \,\,}}}

\def\bigodiv{ {\text{ \large $\mathbf\odiv\hspace{-9.3pt} \div$}} }
\def\bigominus{ {\text{ \large $\mathbf\odiv\hspace{-9.3pt} -$}} }


%\defodiv{{ \odiv\hspace{-7.5pt} \div}}

\newcommand{\diag}[2]{d_{{#1}{#2}}}
\newcommand{\comment}[1]{}
\newcommand{\tell}{{\bf tell}}
\newcommand{\atell}{{\bf atell}}
\newcommand{\ask}{{\bf ask}}
\newcommand{\ostop}{{\bf stop}}
\newcommand{\retract}{{\bf retr}}
\newcommand{\rarrow}{\rightarrow}
\newcommand{\remove}{\rightarrow}
%introdotto per rimuovere le prove
\newcommand{\shortNoProof}[1]{ }

\def\ent{\vdash}
\def\monid{{\mathbf 0}}
\def\1{{\mathbf 1}}
\def\C{{\mathcal C}}
\def\K{{\mathcal K}}
\long\def\comment#1{}
\def\monop{\otimes}
\def\odiv{\, {\ominus\hspace{-7.7pt} \div} \,}
\def\monid{\mathbf{1}}


\newcommand{\RefFig}[1]{Figure \nolinebreak\ref{#1}}
\newcommand\fnsep{\textsuperscript{,}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

\title{Polyadic Soft Constraints~\thanks{Research partially supported by the MIUR PRIN 2017FTXR7S ``IT-MaTTerS''.}}


\author{Laura Bussi\inst{1}, Fabio Gadducci\inst{1}, 
Francesco Santini\inst{2}
} 
	\institute{Dipartimento di Informatica, University of Pisa, Italy \\
		\email{\{filippo.bonchi,laura.bussi,fabio.gadducci\}@unipi.it}
		\and Dipartimento di Matematica e Informatica, University of Perugia, Italy\\
		\email{francesco.santini@unipg.it}
		}
	
\titlerunning{Polyadic Soft Constraints}
\authorrunning{Bussi, Gadducci, and Santini}

\maketitle

\begin{abstract}
We propose a formalism for manipulating soft constraints based on polyadic algebras.
%
The choice of such algebras in place of classical cylindric ones
 simplifies the structure of the partial order of preference values by removing diagonals, 
 a family of constants used for modelling parameter passing and variable substitution,
 whose presence require completeness. 
 Removing diagonals also allows for an easy representation of preference/cost functions in terms of polynomials,
 thus streamlining their manipulation on languages based on (stores of) constraints.
%
Besides presenting the main features of the new formalism,
the paper investigates how the operators of polyadic algebras interact with the residuated 
monoid structure tat is used for representing the set of preference values. 

%bal blah balh blah
%
%The constraint store that describes a \emph{Soft Constraint Satisfaction Problem} (\emph{SCSP}) or the result of agents interaction in \emph{Soft Concurrent Constraint Programming} (\emph{SCCP}), 
%s then represented by a polynomial, as all constraints in general, 
%Our main objective is to provide a blueprint for  developing  such frameworks in practice, by filling the gap between the original algebraic approach and an actual implementation.
\end{abstract}

\keywords{Soft constraints, polyadic algebras, residuated monoids.}

\section{Introduction}\label{sec:intro}

%\subsection{Constraints and constraint programming}
Computer scientists often face combinatorial problems, as e.g. in operational research, artificial intelligence, or circuit design,
and constraints are a tool for naturally modelling such problems. % in a natural way. 
In their simplest form, constraints are just sets of inequations: % over a domain: 
given a set of variables $V$ and a domain of values $D$, 
a constraint over a subset of variables limits the combinations of values that such variables can take. 
Combinatorial problems can thus be easily modelled by constraints: \emph{constraint satisfaction problems} (CSPs)
are defined over a set $V$, a domain $D$ and a set of constraints $C$. Solving a CSP
simply means to find an assignment of the variables such that all its constraints are satisfied. 

\begin{samepage}
Consider, for instance, a problem where we want to respect a given relation among two measures, e.g. $y = 2x$, for $x$ representing the width and $y$ the length of an object. 
Of course, both $x$ and $y$ have to be positive reals and might have to respect some upper bounds, let us say $5$ and $9$. The problem can be formalised as
\begin{itemize}
	\item the set of variables $V$ is $\{x,y\}$;
	\item the domain $D$ is the set of positive reals $\mathbb{R}^+$;
	\item the constraints in $C$ are given by polynomials: $\{2x-y = 0, \ x-5 \leq 0, \ y-9 \leq 0\}$.
\end{itemize}
\noindent
where clearly the assignment $\{x \leftarrow 4, \ y \leftarrow 8\}$ is a solution for the problem.
\end{samepage}

%\smallskip
%\newpage
\emph{Constraint programming} (CP) is a computational framework that allows to implement algorithms for solving CSPs:  
it has been intensively studied and a set of algorithms for solving CSPs have been implemented since the Nineties~\cite{aijour}. 
%
\emph{Concurrent constraint programming} (CCP) extends CP by allowing parallel programs to interact by means of a shared store representing a constraint. 
%
As the basic operations in imperative programming are \emph{read} and \emph{write}, in CP and CCP we have operations to manipulate the store
\begin{itemize}
	\item \emph{tell(c)} adds a constraint \emph{c} to the store;
	\item \emph{ask(c)} checks if a constraint \emph{c} is satisfied, i.e. the store \emph{entails} such a constraint;
\end{itemize}
\noindent
and depending on the domain we may additionally require subtraction (as for example it has been implemented in \cite{lcc}, 
where constraints are formulas in linear logic)
\begin{itemize}
	\item \emph{remove(c)} removes \emph{c} from the store, thus possibly lifting some of the requirements that had been enforced by the constraint. 
	%After the removal, values which were allowed by \emph{c} could be permitted, according on the remaining constraints are satisfied. 
\end{itemize}
%
%Constraint programming have been intensively studied and a set of algorithms for solving CSPs have been implemented since the early Nineties.~\cite{aijour}. 
%Furthermore, CP allows for concurrency by using a blocking \emph{ask} operation: this led to the definition of concurrent constraint programming, 
%where multiple agents can access the store at the same time and perform parallel operations~\cite{popl91}. 
%
In order to model e.g. procedure calls, furthers operators are needed on constraints. 
%
The standard solution~\cite{popl91} is via cylindric algebras: a family of variable-indexed unary operations, %called \emph{cylindrification}, 
for representing existential quantifiers, and a family of constants called \emph{diagonals}, 
for modelling parameters passing and variable substitution.

\smallskip
Despite CSP expressiveness,  
in many real-life situations we need a more flexible way to model problems, 
since some constraints could be ``less important'' than others and might not have to be necessarily satisfied.
%
Soft constraints have been introduced to model this kind of situation. In informal terms, they are classical constraints where a value from a partially ordered set is associated to each instantiation of the variables of a constraint. It is  thus possible to state that a constraint is either  more or less significant than others in order to find a good approximation of the solution, even if not all constraints are satisfied at the same time. 
%
Then, a \emph{soft constraint} is defined as a function of type $(V\to D)\to A$, 
where functions $V\to D$ are assignments of variables in $V$ to a domain $D$ and the values in $A$ represent either cost or preferability, depending on whether representing negative or positive preferences. Combining positive and negative preferences results in what is called a bipolar approach~\cite{posneg}.

To evaluate preferences, the set $A$ is equipped with a semi-lattice structure and, 
to make possible the combination of soft constraints, a monoidal operator. 
Therefore, $A$ turns out to be an idempotent semiring (also called tropical semiring or dioid). 
%
%Many such structures have been proposed.
 For instance, \emph{Fuzzy} semirings associate a constraint to its cost and the aim is to minimise the sum,
  %this falls into the range of negative preferences. 
  while \emph{Probabilistic} semirings associate a constraint to its probability and the aim is to maximise the joint probability.
%Our proposal follows instead a bipolar approach.
A further operation is needed over the set $A$, in order to model the removal of constraints, 
resulting in a residuated monoid: the basics of the formalism within the bipolar approach have been presented in~\cite{ipl17}.

%However, one of the issues that was left open is the representation of constraints in a compact form, since a polynomial presentation is not readily available:
%indeed, tackling this problem has been the starting point of our work.

%\subsection{Cylindric and polyadic algebras for soft constraints}
\medskip

Some extensions of CCP for allowing soft constraints have been already proposed, as for instance in~\cite{scc}, and they required a reworking of the underlying theory.
The starting point has been again the operators of cylindric algebras. However, the use of diagonals for soft constraints puts some strong requirements on the structure of the set of values $A$, 
which are not always met in actual case studies. Moreover, diagonals also present some serious issues in finding a compact representation.

\comment{
Some extensions of CCP for allowing soft constraints have been already proposed, as for instance in~\cite{scc} and they have obviously required a rework of the underlying theory.
in order to provide new operators for modelling variables hiding and procedure calls. These are mainly based on the notion of cylindric algebra, which was defined by Tarsky in 1952 and represents an algebraisation of first order logic. In rough terms, a cylindric algebra is a Boolean algebra provided with unary operations called \emph{cylindrification}, which are a family of variable-indexed operators representing the existential quantifier. Cylindric algebras are also provided with constants, called \emph{diagonals}, which are are used for modelling parameters passing and variables substitution. As said, cylindric algebras have been used in formalisation of constraints, as well as for an algebraisation of relational models~\cite{cylalg}.

Our objective is to develop a more general framework for modelling bipolar preferences in the soft constraint formalism, by providing a new set of operators and defining their properties in order to represent a larger number of interesting case studies.

Polyadic algebras have been introduced by Halmos and they can be considered as a generalisation of cylindric algebras, since they extend the latter and provide a new family of operators which allows for replacing diagonals in modelling variables substitution. Halmos' definition also provides the notion of diagonals and so it's been used so far: indeed, proposed algebras for soft constraints are usually based on complete lattices and structures equipped with diagonals. 

In order to achieve the goal of generalisation, we're completely replacing diagonal elements with a family of weaker operators which recall the given definition of polyadic operators~\cite{sagi2013}. This will allow us to move to semi-lattices and to represent a larger number of case studies. In particular, polynomial functions don't allow for a representation using diagonals: our formalisation fills this gap, providing a comfortable way to express polynomials in the soft constraints formalism.
}%comment

The proposal developed in this paper is to consider polyadic algebras instead of cylindric ones. This means to replace diagonals with a family of polyadic operators (see e.g.~\cite{sagi2013}) that
precisely axiomatise variable substitution, and to investigate how these operators interact with the residuated monoid structure of the set of values $A$.

The benefits are twofold. On the one hand, we relax some of the requirements necessary for $A$: the join semi-lattice on $A$ must be complete for cylindric algebras, while it is not necessary so for polyadic ones. Such relaxation is relevant also for more recent developments on CCP: while in standard denotational models the semantics universe is supposed to have a complete semi-lattice structure, this is not needed with 
the bisimulation semantics introduced in \cite{pippo}.
%
On the other hand, replacing diagonals with polyadic operators allows for a compact -- \emph{polynomial} -- representation of soft constraints.

In Section~\ref{sec:bg} we rephrase some basic definitions for residuated monoids. 
In Section~\ref{newpro} we offer a presentation of polyadic algebras tailored for constraints and we present some results 
concerning the combination of these two structures.
%
These results are used in Section~\ref{sec:softconstraints}, where we provide a novel formalisation of soft constraints in terms of polyadic algebras whose carrier is a residuated monoid. 
%
Finally, in Section~\ref{sec:polynomialsoftconstraints} we introduce a set of constraints that enjoy a polynomials representation 
and we discuss the algebra of linear polynomials with coefficients in $\mathbb{N}$ as a case study.


\paragraph{The (soft) constraints of Catuscia.}
The word ``constraint'' occurs in the titles of 40 publications co-authored by Catuscia. Between 1991 and 1997, most of these papers were devoted to the semantics~\cite{boer1} and analysis~\cite{de1997proving} of Constraint Logic Programming and Concurrent Constraint Programming. In 2001, the latter language was extended to Temporal Concurrent Constraint Programming~\cite{nielsen2002temporal,palamidessi2001temporal}.
%, a rather influential work, that led to the Ph.D. thesis of Frank Valencia. 
Since then, Catuscia has exploited constraints in several applications domains like security \cite{DBLP:conf/iclp/LopezPPRV06}, biological systems \cite{DBLP:conf/birthday/ChiarugiFOP15}, and the modelling of knowledge in social networks \cite{DBLP:conf/concur/KnightPPV12}.

Despite her scientific interest in hard constraints, Catuscia seems to prefer a rather soft approach in her personal and professional relationships: although always surrounded by students, collaborators, and visitors, Catuscia is always available for chatting and joking, and for helping out, both in technical and in personal matters. 
%
Also well-known among friends is her soft spot for the wee hours of the morning. %, both for personal and technical matters.
%
%The first author remembers that during his fellowship at \'Ecole Polytechnique, Catuscia helped him to solve many issues, personal, administrative, and technical. 
%
In particular, the first author recalls that, while working on the afore-mentioned bisimulation semantics for CCP~\cite{pippo}, after many weeks trying hard to prove the main theorem with the other collaborators, he spent one afternoon in Catuscia's office looking together for a proof. When he woke up the morning after, in his mail-box there was a message from her: a beautiful and crystal-clear proof of the long awaited result. This message was sent at about 3 am.

\section{An Introduction to Residuated Monoids}\label{sec:bg}

This section recalls some results on residuated monoids,
which are our chosen algebraic structure for modelling
soft constraints.
%
They are mostly drawn from~\cite{jlamp17}, and they are presented without proofs.
Note however that, to the best of our knowledge, the material from Proposition~\ref{reabs} up
to Example~\ref{nodist2} appears to be original in the literature on costraints.
%
%Section 2.2 presents our personal take on polyadic algebras:
%the standard axiomatisation of e.g.~\cite{sagi2013} has been completely 
%reworked, in order 
%to be adapted to the constraints formalism.
%
%Finally, Section~\ref{cyre} offers some preliminary insights on 
%the laws for polyadic operators in residuated monoids.

\subsection{Preliminaries on Ordered Monoids}\label{sec:lem}

The first step is to define an algebraic structure for modelling preferences,
where it is possible to compare values and combine them.
Our choice falls into the range of \emph{bipolar} approaches, in order to represent both positive and negative preferences: 
we refer to~\cite{ipl17} for a detailed introduction and a comparison with other proposals.
% such as~\cite{xxx}\todo{Manca citazione}.

\begin{definition}[partial order]
	A partial order (PO) is a pair $\langle A, \leq \rangle$ such that
	$A$ is a set and 
	$\leq \,\,\subseteq A \times A$ is a reflexive, transitive, and
	anti-symmetric relation.
	% and $\forall a \in A. \bot\leq a$.
	%
	%A partial order with bottom (POT) is a triple
	%$\langle A, \leq, \bot \rangle$ such that $\langle A, \leq \rangle$ is a PO and
	%$\forall a \in A. \bot \leq a$.
	%
	A (join) semi-lattice (SL) is a PO such that any non-empty finite  subset of $A$ has a
	least upper bound (LUB).
\end{definition}

%We write 
The LUB of a (possibly infinite or empty) subset $X \subseteq A$ is denoted $\bigvee X$, and it is clearly unique.
Should  they exist, $\bigvee A$ and $\bigvee \emptyset$ correspond respectively to the top, denoted as 
$\top$, and to the bottom, denoted as $\bot$, of the PO.
%

%We considered the LUBs of possibly infinite sets just for the sake of simplicity: 
%our proposal would fit also the finite case.
%
%Obviously, Ls also have the greatest lower bound for any subset $Y \subseteq A$.
%In the following we fix a BL ${\mathbb L} = \langle A, \leq, \monid \rangle$.

%\begin{definition}[compact elements]
%An element $a \in A$ is compact (or finite) if whenever $a \leq \bigvee Y$ there exists a finite subset
%$X \subseteq Y$ such that $a \leq \bigvee X$.
%%
%%Let $A^C \subseteq A$ be the set of compact elements of ${\mathbb C}$.
%%Then ${\mathbb C}$ is algebraic if $\forall c \in A. c = \bigvee \{ d \in A^C \mid d \leq c\}$.
%\end{definition}


%Note that for complete lattices the definition of compactness given above coincides with the one using
%directed subsets. It will be easier to generalize it, though, to compactness with respect to the monoidal operator (see Def.~\ref{def:compactness}).
%
%We let $A^C \subseteq A$ denote the set of compact elements of ${\mathbb C}$. Note however
%that $A^C$ might be trivial: indeed, in the the segment $[0, 1]$ of the reals
%with the usual order, only $0$ is a compact element. As we are going to see, the situation for the soft paradigm
%can be more nuanced.
%\marginpar{is algebraicity needed?}
%

\begin{definition}[monoid]
	A (commutative) monoid is a triple
	$\langle A, \monop, \monid \rangle$ such that $A$ is a set, $\monop: A \times A \rightarrow A$ is
	a commutative and associative function, and $\monid \in A$ is the \emph{identity} element,
	namely, $\forall a \in A. a \monop \monid = a$. % where $\monid \in A$ is the \emph{identity} element.
	
	A partially ordered (semi-lattice) monoid is a 4-tuple
	$\langle A, \leq, \monop, \monid \rangle$ such that 	
	$\langle A, \leq \rangle$ is a PO (SL) and $\langle A, \monop, \monid \rangle$ a monoid.
	
%	\noindent
%	A partially ordered monoid is monotone if 
%	satisfying
% 	A weakly ordered monoid is ordered if 
%	\begin{itemize}
%		\item $\forall a, b, c \in A. a \leq b \implies c \monop a \leq c \monop b$.
%	\end{itemize}
%	A semi-lattice monoid is an ordered (weakly so, respectively) monoid 
%	such that its underlying PO is an SL. 
\end{definition}

As usual, we use the infix notation: $a \monop b$ stands for $\monop(a,b)$.

\begin{definition}[distributivity]
\label{dist}
Let $\langle A, \leq, \monop, \monid \rangle$ be a semi-lattice monoid.
It is distributive if
	for  any  non-empty finite  $X \subseteq A$
	\begin{itemize}
		\item $\forall a \in A.\,  a \monop  \bigvee X = \bigvee \{a \monop x \mid x \in X\}$.
	\end{itemize}

\end{definition}

Note that distributivity implies that $\otimes$ is monotone with respect to $\leq$.
\begin{remark}
% i.e., it holds
%	\begin{itemize}
%		%\item 
%		$\forall a, b, c \in A. a \leq b \implies c \monop a \leq c \monop b$.
%	\end{itemize}

	It is almost straightforward to show that our proposal encompasses many other formalisms in the literature.
	Indeed, distributive semi-lattice monoids are \emph{tropical} semirings (also known as dioids), 
	namely, semirings with an idempotent sum operator $a \oplus b$, which in our formalism is obtained as
	$\bigvee \{a, b\}$.
	% that is idempotent.
	%~\cite{tropical}. 
	If $\monid$ is the top of the SL we end up 
	in \emph{absorptive} semirings~\cite{golanShort}, 
	which are known as $c$-semirings 
	in the soft constraint jargon~\cite{jacm97} (see e.g.~\cite{ecai06} for a brief survey on residuation 
	for such semirings).
	%
%	%Indeed, it is precisely the lack of the latter requirement on $\monid$ that makes ReSLs suitable for modelling bipolar 
%	%preferences:
	Note that requiring the monotonicity of $\otimes$ and imposing $\monid$ to be the top of the partial order
	means that preferences are negative, i.e., 
	that it holds $\forall a, b \in A. a \monop b \leq a$.
%	%, and that $\forall a, b \in A. a \leq b \implies \monid = b \odiv a$.
%	%
\end{remark}

\begin{example}
Given a (possibly infinite) set $V$ of variables, two semi-lattice monoids are going to play a key role in the following sections.

The first one is the semi-lattice monoid 
$\mathbb{M}(V) = \langle 2^V_{fin}, \subseteq, \cup, \emptyset \rangle$
of finite sub-sets of $V$, with the usual order given by sub-set inclusion.
%\todo{come in un commento nel seguiro, non trovo spiegazione della $f$ in $2^V_f$}

For the second one, we start by defining the support of an endofunction $f\colon V \to V$ as the set $sv(f) = \{ x \in V \mid f(x)\neq x \}$ and
$F(V)$ as the set of functions $f\colon V \to V$ with finite support.
The semi-lattice monoid of interest is  $\mathbb{F}(V) = \langle F(V), id, \circ, \iota \rangle$ where 
$\iota$ is the identity function,  $\circ$ is function composition and $id$ is the discrete ordering on $F(V)$.
\end{example}

\bigskip
%
% COMMENTATO DA FILIPPO
%
%\begin{remark}
%The developments reported in Section~\ref{cypo} could be stated also for \emph{infinite} subsets 
%and for functions whose support is not necessarily finite. More on this later on.
%\end{remark}

%$a, b \in A$.
%
%The monoidal operator can be defined for any finite multiset: it is given for a family of elements
%$a_i \in A$ indexed over a finite set $I$, and it is denoted by
%$\bigotimes_{i \in I} a_i$.
%%
%Whenever for an index $I$ all the $a_i$'s are different,
%we simply write $\bigotimes S$ instead of $\bigotimes_{i \in I} a_i$
%for the set $S = \{a_i \mid i \in I\}$.
%%
%Conventionally, we will also usually denote $\bigotimes \emptyset = \top$.
%
%%smallskip
%%In the following we fix a IM ${\mathbb M} = \langle A, \monop, \monid \rangle$.
%
%We now move our attention to the domain of values we are going to consider.

\subsection{Remarks on Residuation}\label{sec:ror}
It is often needed to be able to ``remove'' part of a preference, due e.g. 
to the non-monotone nature of the language at hand
for manipulating constraints. 
%
The structure of our choice is given by residuated monoids~\cite{golanShort}. 
%
They introduce a new operator $\odiv$, which represents a ``weak'' (due to the presence of partial orders) inverse of $\otimes$.

\begin{definition}[residuation]\label{def:repo}
	A residuated monoid (RePO) is a 5-tuple $\langle A, \leq, \monop, \odiv, \monid \rangle$ such that
	$\langle A, \leq, \monop, \monid \rangle$ is a partially ordered monoid and
	$\odiv: A \times A \rightarrow A$ is a function satisfying 
	\begin{itemize}
		\item $\forall a, b, c \in A. b \monop c \leq a \iff c \leq a \odiv b$.
	\end{itemize}
	An ReSL is an RePO such that the underlying PO is a SL.
\end{definition}

%In the following sections on oft CCP, we will often use absorptive RePOs, i.e., such that 
%	\begin{itemize}
%		\item[] $\forall a, \in A. a \leq 1$.
%	\end{itemize}
%
%However, 

%Residuation is monotone on the first argument: 
%$\forall a, b, c \in A. a \leq b \implies a \odiv c \leq b \odiv c$.
%Among other things, n
In order to confirm the intuition about weak inverses,
Lemma~\ref{lemma:residuation} below precisely states that residuation conveys the meaning of 
an approximated form of subtraction.
% which can be used to remove a constraint from another.
% operator.

\begin{lemma}\label{lemma:residuation}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an RePO.
	Then
	\begin{itemize}
		\item $\forall a, b \in A.\, a \odiv b = \bigvee \{ c \mid b \monop c \leq a\}$,
	\end{itemize}
\end{lemma}

\shortNoProof{
\begin{proof}
	By definition $a \odiv b$ is an upper bound of 
	$\{ c \mid b \monop c \leq a\}$ and $b \monop (a \odiv b) \leq a$.
	%
%	The latter property ensures the monotonicity of $\odiv$ on the first argument,
%	since by definition $a \odiv c \leq b \odiv c$ iff $c \monop (a \odiv c) \leq b$.
	%
%	As for the  monotonicity of $\monop$, it suffices to note that by definition
%	$a \leq (b \monop a) \odiv b$ and also by definition $c \monop a \leq c \monop b$ iff 
%	$a \leq (c \monop b) \odiv c$.
\qed
\end{proof}
}

%Note that by commutativity, 
%Thus $\monop$ is monotone (on both arguments), and
%the underlying monoid is ordered.
%while $\odiv$  is clearly anti-monotone on the second argument: 

In order to ease the verification of the algebraic structure, it is often needed
a characterisation of residuation via simpler properties,
as the ones given below.

\begin{lemma}
\label{mono}
Let $\langle A, \leq, \monop, \monid \rangle$ be a partially ordered monoid  and
	$\odiv: A \times A \rightarrow A$ a function. Then $\langle A, \leq, \monop, \odiv, \monid \rangle$ is an RePO if and only if
	\begin{itemize}
		\item $\forall a, b \in A. b \monop (a \odiv b) \leq a \leq (b \monop a) \odiv b$,
		\item $\forall a, b, c \in A.\, a \leq b \implies a \otimes c \leq b \otimes c$ and $a\odiv c \leq b \odiv c$.
\end{itemize}
\end{lemma}

\shortNoProof{
\begin{proof} ($\Longrightarrow$)
The first item is immediate. Now, let $a \leq b$. Since $b \leq (b \otimes c) \odiv c$ and 
$c \otimes (a \odiv c) \leq a$, the second item follows.

($\Longleftarrow$)
Using the monotonicity of $\odiv$ from $b \monop c \leq a$ we get
 $(b \monop c) \odiv b \leq a \odiv b$, and by the first item
 $c \leq a \odiv b$.
 %
 From the latter by the monotonicity of $\otimes$ we get
 $b \otimes c \leq b \otimes (a \odiv b)$, and by the first item
 $b \monop c \leq a$.
 %
%	Immediate: $a \odiv b$ is an upper bound of 
%	$\{ c \mid b \monop c \leq a\}$ and $b \monop (a \odiv b) \leq a$.
	%
%	The latter property ensures the monotonicity of $\odiv$ on the first argument,
%	since by definition $a \odiv c \leq b \odiv c$ iff $c \monop (a \odiv c) \leq b$.
	%
%	As for the  monotonicity of $\monop$, it suffices to note that by definition
%	$a \leq (b \monop a) \odiv b$ and also by definition $c \monop a \leq c \monop b$ iff 
%	$a \leq (c \monop b) \odiv c$.
\qed
\end{proof}
}

It is easy to show that in any RePO the $\odiv$ operator is also anti-monotone on the second argument, i.e., 
$\forall a, b, c \in A.\, a\leq b \implies  c\odiv b \leq c \odiv a$.
%
Other properties are also straightforward, such as 
$\forall a\in A. \monid \leq a \odiv a$, which in turn implies 
that $\forall a\in A. a \monop (a \odiv a) = a$ and
%
%, and \emph{iii)} $a \odiv (b \monop c) = (a \odiv b) \odiv c$.
%should $\monop$ be idempotent, $b \leq a$ implies $a \odiv b = a$.
%
$\forall a, b \in A. a < b \implies \monid \not \leq a \odiv b$, where
$a < b$ means $a \leq b$ and $a \neq b$.
%
%Residuation is monotone on the first argument:
%$\forall a, b, c \in A. a \leq b \implies a \odiv c \leq b \odiv c$.
%%falsa and if $b \leq a$, then $a \odiv b = \monid$. For more properties of residuation we refer to \cite[Table~4.1]{resbook}.
%
%
The latter fact suggests the definition below, which identifies sub-classes 
of residuated monoids that are suitable for an easier manipulation
of constraints (see e.g.~\cite{ecai06}).

\begin{definition}[localisation / invertibility]
	An RePO $\langle A, \leq, \monop, \odiv, \monid \rangle$ is
	\begin{itemize}
		\item
		\emph{localised} if $\forall a, b \in A. a \leq b \implies a \odiv b \leq \monid$;
		\item
		\emph{invertible} if $\forall a, b \in A. a \leq b \implies b \monop (a \odiv b) = a$.
	\end{itemize}
\end{definition}

Note that if a RePO is localised then $\forall a \in A. a \odiv a = \monid$.
%\marginpar{all RePO are localized?}

\begin{remark}\label{rmk:soft}
	Some well-known structures used for soft constraints are the 
	%\emph{Boolean} ($\langle \{\mathit{false},\mathit{true}\}, \mathit{false} \leq \mathit{true}, \wedge, \mathit{false}, \mathit{true}\rangle$), 
	\emph{Fuzzy} ($\langle [0,1], \leq,$ $\min, 1 \rangle$), \emph{Probabilistic} ($\langle [0,1], \leq,\allowbreak\times, 1 \rangle$), 
	and \emph{Tropical}   ($\langle \mathbb{R}^+, \geq, +, 0 \rangle$) semirings, for $\geq$ the inverse of the standard order 
	(thus $0$ the top of the SL). In all these cases the underlying monoids 
	are both invertible and localised, thus
	%
	the $\odiv$ operator can be also used to
	(partially) relax constraints (see again~\cite{ecai06}).
\end{remark}

Moving to ReSLs, next lemma ensures that residuation implies distributivity.

\begin{lemma}
	\label{dist2}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL.
	Then the underlying SL is distributive.
%	 and $X \subseteq A$ a finite set.
%	Then
%	\begin{itemize}
%		\item $\forall a \in A.\, a \monop  \bigvee X = \bigvee \{a \monop x \mid x \in X\}$.
%	\end{itemize}
\end{lemma}

\shortNoProof{
\begin{proof} Let $X \subseteq A$ be a finite non-empty set. 	
	%\paragraph{$\bigvee \{a \monop x \mid x \in X\} \leq a \monop  \bigvee X$}
	\[\forall x \in X.\, x \leq \bigvee X %\implies %\forall x \in X.\, x \leq (a \monop \bigvee X) \odiv a \implies\]
	\implies \forall x \in X.\, a \monop x \leq a \monop \bigvee X \implies \bigvee \{a \monop x \mid x \in X\} \leq a \monop  \bigvee X .\]

	%So, let us assume that $X$ is inhabited.
	%\paragraph{$a \monop  \bigvee X \leq \bigvee \{a \monop x \mid x \in X\}$}
	\[\forall y \in X.\, a \monop y \leq \bigvee \{a \monop x \mid x \in X\} \implies 
	\forall y \in X.\, y \leq (\bigvee \{a \monop x \mid x \in X\}) \odiv a \implies\] 
	\[ \implies \bigvee X \leq (\bigvee \{a \monop x \mid x \in X\}) \odiv a \implies 
	a \monop \bigvee X \leq \bigvee \{a \monop x \mid x \in X\} .\] 
\qed
\end{proof}
}
%Note that the proof does not require that $\otimes$ is monotone, which is thus a derived property.
%
Distributivity holds also for the empty set and for infinite sets, if the necessary LUBs exist.
%
Instead, it holds only partially for $\odiv$: this follows directly from the monotonicity of $\odiv$ on the first argument, 
since it implies that $x \odiv a \leq \bigvee X \odiv a$ for all $x \in X$.

\begin{lemma}
	\label{distodiv}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL and $X \subseteq A$ a finite non-empty set. Then 
	\begin{itemize}
		\item $\forall a \in A.\, \bigvee \{ x \odiv a \mid x \in X \} \leq \bigvee X \odiv a$
	\end{itemize}	
\end{lemma}

\shortNoProof{
\begin{proof}
Straightforward, since by the monotonicity of $\odiv$ in the first argument (Lemma~\ref{mono}) we get
% \[\forall x \in X.\,a \otimes (x \odiv a) \leq x \implies\]
 %\[\forall x \in X.\,a \otimes (x \odiv a) \leq \bigvee X \implies\]
 $\forall x \in X.\,x \odiv a \leq \bigvee X \odiv a$, which implies
 $\bigvee \{ x \odiv a \mid x \in X\} \leq \bigvee X \odiv a$.
% \[\]
\qed
\end{proof}
}

%\begin{remark}
Also this inequation holds for the empty set and for infinite sets, if the necessary LUBs exist.
%
Moreover, it also holds that $\bigvee \{ a \odiv x \mid x \in X \} \geq a \odiv \bigvee X$, since $\odiv$ is anti-monotone on the second argument.
%\end{remark}

\begin{proposition}\label{reabs}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL. The following are equivalent
	\begin{enumerate}
		\item $\forall a \in A.\, a \leq \1$
		\item $\forall a \in A.\, \1 \odiv a = \1$		
		\item $\forall a, b \in A.\, a \leq b \implies b \odiv a = \1$
	\end{enumerate}	
\end{proposition}

\shortNoProof
{
\begin{proof}
Note that $1$ immediately implies both $2$ and $3$, since by definition $a \leq b$ implies $\1 \leq b \odiv a$
and $\1$ is the top of the partial order.

For the second step, first note that both properties implies that $\1 \odiv a \leq \1$ for all $a \in A$. This is immediate
for $2$. As for $3$, %let us assume that $b \odiv a \leq \1$, and
consider $b = \bigvee \{\1, a \}$. By Lemma~\ref{distodiv} we have that
$\bigvee \{\1 \odiv a, a \odiv a\} \leq \bigvee \{\1, a \} \odiv a$. 
Hence, $\1 \odiv a \leq \1$ for all $a \in A$, and the result follows.

Finally, note that $\1 \odiv a \leq \1$ for all $a \in A$ implies that $\1 \odiv (\1 \odiv c) \leq \1$ for all $c \in A$, 
and since it always holds
that $c \leq \1 \odiv (\1 \odiv c)$, then $3$ implies $1$.
\qed
\end{proof}
}

%\begin{remark}
%In general, given an ReSL $\mathbb{M} = \langle A, \leq, \otimes, \odiv, \monid \rangle$, if $A \subseteq B$ such that $B(\otimes)$ is a group and $\odiv$
% is the inverse of $\otimes$, then $\mathbb{M}$ is fully $%\odiv$-distributive, which follows from $\mathbb{M}$ is distributive for $\otimes$. \\
%Consider, for istance, $\mathbb{M} = \langle \{0,...,5\},\geq,\oplus,\ominus,0 \rangle$, where $\oplus$ and $\ominus$ are the bounded sum and subtraction (e.g. $2 \oplus 4 = 5$, $2 \ominus 4 = 0$): 
%it is clear that, in this case, distributivity holds for $\ominus$, as long as $a \geq b \implies b \ominus a = 0$. \\
%\todo{un esempio dove $\odiv$ non distribuisce}
%In the following example it is shown that distributivity for $\odiv$ could hold partially, since we choose a residuation operator which is not the inverse of $\otimes$.
%\end{remark}

\begin{remark}\label{rmk:softUnit}
The proposition above provides an important characterisation for all absorptive ReSLs, including all those mentioned in Remark~\ref{rmk:soft}.
\end{remark}

There are some important classes of ReSLs  such that $\odiv$ is easily proved to be distributive in the first argument,
while it is not so with respect to the second argument, not even in the absorptive case.

\begin{lemma}
	\label{distodiv2}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL such that $\langle A, \leq \rangle$ is a total order and $X \subseteq A$ a finite non-empty set. Then 
	\begin{itemize}
		\item $\forall a \in A.\, \bigvee \{ x \odiv a \mid x \in X \} = \bigvee X \odiv a$
	\end{itemize}	
\end{lemma}

\shortNoProof{
\begin{proof}
If $\langle A, \leq \rangle$ is a total order and $X$ is finite and non-empty we have that $\bigvee X \in X$, and since $\odiv$ 
is monotone on the first argument (see Lemma~\ref{mono}) the result follows.
\qed
\end{proof}
}

\begin{example}
\label{nodist2}
%Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL such that $\langle A, \leq \rangle$ is a total order.
%Then, it holds that $\bigvee \{ x \odiv a \mid x \in X \} = \bigvee X \odiv a$ for all elements $a$ and (finite, non-empty) subsets $X$.
%In fact, if $\langle A, \leq \rangle$ is a total order and $X$ is finite and non-empty we have that $\bigvee X \in X$, and since $\odiv$ 
%is monotone on the first argument (see Lemma~\ref{mono}), the result follows.
%
Let $n$ be a positive integer and $[n] = \{0, \ldots, n\}$ the segment of integers from $0$ to $n$. We can now define the (bounded) monoid $\mathbb{M}_n$ 
as the tuple $\langle [n], \geq, \oplus, \ominus, 0 \rangle$, where $\oplus$ and $\ominus$ are the bounded sum and subtraction, 
which are given as $m\oplus p = min\{n, m+p\}$ and $m\ominus p = max\{0,m-p\}$.

Now, it can be shown that $\mathbb{M}_n$ is an absorptive ReSL, and since it is a total order,
$\ominus$ is  distributive on the first argument.
%
However, in general it is not distributive on the second one. Consider an integer $m$ such that 
$m \neq n$ and the set $\{m, m+1\}$:
we then have that $(m+1) \ominus \bigvee\{m, m+1\} = 1$,
while instead $\bigvee\{(m+1) \ominus m, (m+1) \ominus (m+1)\} = 0$.
\end{example}

\comment{
\begin{example}
Given $A = \{0,a,b,c,d,e\}$, consider the following partial order:
	\begin{center}
		\begin{tikzpicture}
			\node (top) at (0,0)  {$0$};
			\node (a) [below of= top] {$a$};
			\node [below left of=a] (left) {$b$};
			\node [below right of=a] (right) {$c$};
			\node (d) [below right of=left] {$d$};
			\node (e) [below of=d] {$e$};
			\draw [thick] (top) -- (a);
			\draw [thick] (a) -- (left);
			\draw [thick] (a) -- (right);
			\draw [thick] (left) -- (d);
			\draw [thick] (right) -- (d);
			\draw [thick] (d) -- (e);
		\end{tikzpicture}
	\end{center}
and $\mathbb{M} = \langle A, \geq, \otimes, \odiv, 0 \rangle$, where $\otimes$ and $\odiv$ are defined as follows:
\begin{center}
	\begin{tabular}{@{} *{7}{c} @{}}
	\\ $\otimes$ \ & 0 \ & a \ & b \ & c \ & d \ & e
	\\ 0 \ & 0 \ & a \ & b \ & c \ & d \ & e
	\\ a \ & a \ & b \ & c \ & d \ & e \ & f
	\\ b \ & b \ & c \ & d \ & d \ & e \ & e
	\\ c \ & c \ & d \ & d \ & d \ & e \ & e
	\\ d \ & d \ & e \ & e \ & e \ & e \ & e
	\\ e \ & e \ & e \ & e \ & e \ & e \ & e
	\end{tabular}
\\	
	\begin{tabular}{@{} *{7}{c} @{}}
	\\ $\odiv$ \ & 0 \ & a \ & b \ & c \ & d \ & e
	\\ 0 \ & 0 \ & 0 \ & 0 \ & 0 \ & 0 \ & 0
	\\ a \ & a \ & 0 \ & 0 \ & 0 \ & 0 \ & 0
	\\ b \ & b \ & a \ & 0 \ & 0 \ & 0 \ & 0
	\\ c \ & c \ & a \ & 0 \ & 0 \ & 0 \ & 0
	\\ d \ & d \ & c \ & c \ & b \ & 0 \ & 0
	\\ e \ & e \ & d \ & b \ & c \ & a \ & 0
	\end{tabular}
\end{center}
Then $\mathbb{M}$ is an absorptive ReSL with $0$ the top of the partial order, since it behaves as the ReSL in the example above, except for $b$ and $c$: thus, in this case, $\bigvee \{b,c\} = a$. \\
It's now easy to show that $\odiv$ is not distributive for the first argument: $\bigvee{b \odiv a, c \odiv a} = a$ and $\bigvee\{b,c\} \odiv a = a \odiv a = 0$.
\end{example}

%
%We can proove $\bigvee X \odiv a = \bigvee \{ x \odiv a \mid x \in X \}$ under the following hypotesis.
%
%\begin{lemma}
%	\label{distodiv2}
%	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL.
%	If $a \otimes (x \odiv a) = x = (a \otimes x) \odiv a$, then $\bigvee X \odiv a = \bigvee \{ x \odiv a \mid x \in X \}$.
%\end{lemma}
%
%\begin{proof}
% \[\bigvee X = \bigvee \{ a \otimes (x \odiv a) \mid x \in X \} \implies\]
% \[\bigvee X = a \otimes \bigvee \{ x \odiv a \mid x \in X \} \implies\]
% \[\bigvee X \odiv a = (a \otimes \bigvee \{ x \odiv a \mid x \in X\}) \odiv a \implies\]
% \[\bigvee X \odiv a = \bigvee \{ x \odiv a \mid x \in X\}.\]
% \[\]
%\end{proof}
%
%[Qui avevi fatto una correzione, mettendo nell'ipotesi una disuguaglianza al posto della seconda uguaglianza, ma in quel modo non potrei provare l'ultimo passaggio, quindi te la rispedisco cos\`{i}. 
%Magari ne discutiamo quando ci vediamo.]
%\\

%Distributivity over $\bigvee$ implies that $\monop$ is
%monotone in both arguments.
%%as well as $\forall a \in A. a \monop \bot = \bot$.

%%
%In the following, we fix a BLIM ${\mathbb S} = \langle A, \leq, \monop \rangle$.
%%
%The next step is to provide a suitable notion of infinite composition. The definition below is taken from~\cite{CLIM}
%(but see also~\cite[p.~42]{golan}).
%
%\begin{definition}[infinite composition]
%Let $I$ be a (possibly countable) set of indexes. Then, the composition $\bigotimes_{i \in I} a_i$
%is defined as $\bigvee_{J \subseteq I} \bigotimes_{j \in J} a_j$ for all finite subsets $J$.
%\end{definition}

%%\marginpar{distributivity wrt. $\vee$ or wrt. $\wedge$ coincide?}
%Thanks to distributivity, we can show that
%$\bigotimes$ is monotone, i.e., $\forall j \in I. a_j \leq b_j \implies
%\bigotimes_{i \in I} a_i \leq \bigotimes_{i \in I} b_i$.

%We now extends the notion of compactness.
%
%\begin{definition}[$\monop$-compact elements]\label{def:compactness}
%An element $a \in A$ is $\monop$-compact (or $\monop$-finite) if whenever $a \leq \bigotimes_{i \in I} a_i$
%then there exists a finite subset $J \subseteq I$ such that $a \leq \bigotimes_{j \in J} a_j$.
%
%Let $A^\monop \subseteq A$ be the set of $\monop$-compact elements of ${\mathbb S}$. Then ${\mathbb S}$ is
%$\monop$-algebraic if $\forall c \in A. c = \bigotimes \{ d \in A^\monop \mid d \leq c\}$.
%\marginpar{now $\monop$-algebraicity is incorrect}
%\end{definition}

%We let $A^\monop \subseteq A$ denote the set of $\monop$-compact elements of ${\mathbb S}$.
%%
%It is easy to show that a compact element is also $\monop$-compact.
%%
%Indeed, the latter notion is definitively more flexible.
%%
%Let us consider again the segment $[0, 1]$ of the reals, yet now with the inverse of the usual order (as used
%in the probabilistic SCPs). Instead of the LUB, an alternative monoidal
%product can be just the multiplication.
%%
%Since any infinite multiplication tends to $0$, then all the elements are
%$\monop$-compact, except the top element itself, that is, precisely $0$.
%\marginpar{is $\monop$-algebraicity needed?}
}

\comment{
\subsection{On residuation and semirings}

We now consider \emph{semirings} equipped with a partial order~\cite[Chapter~2]{golanShort}.

\begin{definition}[semirings]
	A (commutative) semiring is a 5-tuple
	$\langle A, \monop, \monop, \monid, \1 \rangle$ such that $\langle A, \monop, \monid \rangle$
	and $\langle A, \monop, \1 \rangle$ are (commutative) monoids
	satisfying
	\begin{itemize}
		\item $\forall a \in A. a \monop \monid = \monid$
		\item $\forall a, b, c \in A. a \monop (b \monop c) = (a\monop b) \monop (a \monop c)$
	\end{itemize}
	An ordered semiring is a 6-tuple
	$\langle A, \leq, \monop, \monop, \monid, \1 \rangle$
        such that  $\langle A, \leq, \monop, \monid \rangle$ is an ordered monoid and 
   	$\langle A, \monop, \monop, \monid, \1 \rangle$ a semiring satisfying
	\begin{itemize}
			\item $\forall a, b, c \in A. a \leq b \wedge \monid\leq c \implies c \monop a \leq c \monop b$
	\end{itemize}
\end{definition}

We often use an infix notation, as $a \monop b$ for $\monop(a,b)$.


[A QUESTO PUNTO BISOGNA VEDERE QUALI DI QUESTE TRE PROPRIETA'
DELL'ordered SEMIRING POSSONO DISCENDERE DA QUELLE DELLA RESIDUAZIONE,
IN MODO DA AVERE GLI EQUIVALENTI DEI LEMMA 3 E 4]

[ MA 1 MI SERVE A QUALCOSA?]

\begin{definition}[residuation, II]
	A residuated semiring (ReS) is a 7-tuple $\langle A, \leq, \monop, \odiv, \monop, \monid, \1 \rangle$
	such that	$\langle A, \leq, \monop, \odiv, \monid \rangle$
	 is a residuated monoid and $\langle A, \leq, \monop, \monop, \monid, \1 \rangle$ an ordered semiring,
	  satisfying 
	\begin{itemize}
            ????
	\end{itemize}
	A residuated SSL (ReSSL) is an ReS such that the underlying PO is a SL.
\end{definition}

[COSA PUO' SERVIRE COME ASSIOMA?]

%In the following sections on oft CCP, we will often use absorptive RePOs, i.e., such that 
%	\begin{itemize}
%		\item[] $\forall a, \in A. a \leq 1$.
%	\end{itemize}
%
%However, 
}

\comment{
Indeed, there are many classes of absorptive and idempotent ReSLs such that $\odiv$ 
is not distributive in either arguments.

\begin{example}
\label{notdistr}
First of all, note that a complete sup-lattice $\langle A, \leq \langle$ (i.e., admitting a sup for all subsets 
of $A$) can be turned into a ReSL. Indeed, $\otimes$ is just the meet, so we have that 

\begin{itemize}
\item $a \otimes b = \bigvee \{c \mid c \leq a \wedge c \leq b\}$
\item $a \odiv b = \bigvee \{c \mid c \otimes b \leq a\}$
\end{itemize}


$$x \otimes y = \bigg \{\begin{array}{ll}
	\1 & \mbox{ if } y \leq x \\
	x & \mbox{ if } y = \1 \\
	\bot & \ otherwise
	\end{array}$$

both meetand divis




the bounded sum $\oplus$ is here idempotent, $0$ is still 
the identity. We can make it int


of three otherwise unrelated elements, 
so that for all elements $x$ we have $x \otimes x = \1 \otimes x = x$ \
and furthermore $a \otimes b = a \otimes c = b \otimes c  = \1$.

We now add the bottom element $\bot$, in order to obtain a complete lattice.
Then $\otimes$ is extended in the expected way, so that $\bot$ is absorbing.
%
The resulting semi-lattice monoid is absorptive and residuated, with $\odiv$ defined as

$$x \odiv y = \bigg \{\begin{array}{ll}
	\1 & \mbox{ if } y \leq x \\
	x & \mbox{ if } y = \1 \\
	\bot & \ otherwise
	\end{array}$$
%
Thus, $\odiv$ does not distribute, since 
$\bigvee \{a \odiv c, b \odiv c\}  = \bot < \1 = \1 \odiv c = \bigvee \{a, b\} \odiv c$.
\end{example}
}

\comment{
\begin{example}
\label{notdistr}
Let us consider the monoid $S = \langle \{p,u,n,t\}, \otimes_s, u \rangle$ (with $t$ the top 
of three otherwise unrelated elements): 
$p$ and $n$ intuitively represent the sign of an integer, $t$ tells us that 
the sign cannot be determined, $u$ is the zero
and $\otimes_s$ (which is idempotent) tells us the sign of the addition of two integers, so that 
for all elements $x$ we have
\[x \otimes_s x = u \otimes_s x = x \mbox{  and  } t \otimes_s x = p \otimes_s n = t\]
%
We now add the bottom, in order to obtain a complete lattice.
The $\otimes_s$ is extended in the expected way,  so that $\bot$ is absorbing.
%
Intuitively, $\bot$ states that an element is unsigned:
a pattern the reader familiar with abstract interpretation formalisms will recognise.

The resulting semi-lattice monoid is residuated, with $\odiv$ defined as

$$x \odiv y = \bigg \{\begin{array}{ll}
	t & y \leq x \\
	\bot & \ otherwise
	\end{array}$$
%
Thus, $\odiv$ does not distribute, since 
$\bigvee \{p \odiv n, u \odiv n\}  = \bot < \bigvee \{p, u\} \odiv n = t \odiv n = t$.
\end{example}
}

\section{An Alternative Proposal for Costraint Manipulation}
\label{newpro}

This section presents our personal take on polyadic algebras for ordered monoids:
the standard axiomatisation of e.g.~\cite{sagi2013} has been completely 
reworked, in order to be adapted to the constraints formalism.
%
We close the section by offering some preliminary insights on 
the laws for polyadic operators in residuated monoids.

\subsection{Cylindric and Polyadic Operators for Ordered Monoids}
\label{cypo}
We now introduce two families of operators 
%(cylindric and polyadic ones) 
that will be used
for modelling variables hiding and substitution, which represent
key features in languages for manipulating constraints.
%
One is a well-known abstraction for existential quantifiers,
the other an axiomatisation of the notion of
substitution, and it is proposed as a weaker  alternative 
to diagonals~\cite{popl91}, the standard tool for modelling 
equivalence in constraint programming.\footnote{``Weaker 
alternative'' here means that diagonals allow for axiomatising
substitutions at the expenses of working with complete
partial orders: see e.g.~\cite[Definition 11]{jlamp17}.}
%

\smallskip
Our first step is the introduction of a technical notion that allows for 
factorising the common properties in the definition of the two families of operators.

\begin{definition}[pomonoid action]
\label{pomo}
Let $\mathbb{M} = \langle A, \leq, \monop, \monid \rangle$ be a partially ordered monoid and $\mathbb{P} = \langle S, \leq \rangle$ a partial order.
A pomonoid action of $\mathbb{M}$ on $\mathbb{P}$ is a function $\phi: A \times S \rightarrow S$ such that
	\begin{itemize}
	     \item $\forall s \in S.\ \phi(\monid, s) = s$,
         \item $\forall a, b \in A,\ s \in S.\ \phi(a, \phi(b, s)) = \phi(a \otimes b, s)$,
         \item $\forall a, b \in A,\ s, t \in S.\ a \leq b\, \wedge\, s \leq t \implies \phi(a, s) 
         \leq \phi (b, t)$.
            % \item $\forall a, b \in A,\ s \in S.\ a \leq b \implies \phi(a, s) \leq \phi (b, s)$.
	\end{itemize}
\end{definition}

The first two requirements just state
that $\phi$ is a monoid action of $\mathbb{M}$ on $S$, while the latter states that $\phi$ is monotone. Sometimes, we say that $\mathbb{P}$ is an $\mathbb{M}$-PO.

\subsubsection{Cylindric operators.}
We fix a partially ordered monoid $\mathbb{S} = \langle A, \leq, \monop, \monid \rangle$
and a set $V$ of variables, and we then define a family of cylindric operators axiomatising existential quantifiers.

\begin{definition}[cylindrification]\label{cyli}
	A cylindric operator $\exists$ over $\mathbb{S}$ and $V$ is a pomonoid action
	$\exists: V \times A \rightarrow A$ such that for all $X \subseteq V$
	%\todo{$2_f^V$ non e' stato definito prima e/o f non si sa cosa e' qui}
	\begin{enumerate}
%	     \item $\forall a \in A.\ \exists(\emptyset, a) = a$,
%             \item $\forall a \in A.\ \exists(X, \exists(Y, a)) = \exists(X \cup Y, a)$,
 %            \item $\forall a, b \in A.\ X \subseteq Y\wedge a \leq b \implies  \exists(X, a) = \exists(Y, b)$,
	     \item $\exists(X, \monid) = \monid$,
	     \item $\forall a,b \in A.\ \exists(X, a \monop \exists(X, b)) = \exists(X, a) \monop \exists(X, b)$.
	\end{enumerate}
	
	\noindent Let $a \in A$. The \emph{support} of $a$ is the set of variables $sv(a) = \{ x \mid \exists(\{x\}, a) \neq a\}$. 
	% and the set of unsupported variables of $a$ is the set of variables $uv(a) =  V \setminus sv(a)$.
\end{definition}

If $X = {x}$, we write $\exists_x$.

%Note that, since by Definition~\ref{pomo} we have $\exists(\emptyset, a) = a$, the requirements of Definition~\ref{cyli} trivially hold 
%whenever $X$ is the empty set.
%
%The first two conditions tell us that $\exists$ is a monoid action of $M(V)$ over $A$. Condition $3$ states
%that $\exists$ is a monotone function. Finally, the last two conditions state how $\exists$ interacts with the 
%monoidal structure on $\mathbb{S}$.
%
%\begin{remark}
%TODO bisogna vedere cosa altro serve, e se qualche propriet\`a \`e derivata.
%Cosa succede se $\mathbb{S}$ \`e un SL? Questo impatta sui LUB in M(V)?
%\end{remark}
%
%
%Note also that $\exists(X, \monid) = \monid$ would be a consequence of monotonicity,
%should $\monid$ be the top element. Also, the support is not necessarily finite.
%Finally, and importantly, note that 
%$X \cap sv(\exists(X, a)) = \emptyset$.

%\smallskip
%In the following, we often use $\exists_X a$ for $\exists(X, a)$, and $\exists_x a$ whenever $X = \{x\}$.

\subsubsection{Polyadic operators.}
We now move to define a family of operators axiomatising substitutions.  
They interact with quantifiers, thus, beside a partially ordered monoid $\mathbb{S}$
and a set $V$ of variables, we fix a cylindric operator $\exists$ over ${\mathbb S}$ and $V$.

As for notation, for a function $\sigma: V \rightarrow V$ and a set $X \subseteq V$, we denote by 
$\sigma \mid_{X}: X \rightarrow V$ the obvious restriction, and
by $\sigma^{c}(X) \subseteq V$ the counter-image of $X$ along $\sigma$.
%~\footnote{We are not going to need the other standard component proposed in the literature , i.e., \emph{diagonals}: a %family of elements $d_{x, y} \in A$ indexed by pairs of elements in $V$.}


\begin{definition}[polyadification]
	\label{def:poly}
	A polyadic operator $s$ for $\exists$ is a pomonoid action $s: F(V) \times A \rightarrow A$
	such that for all $X \in 2_{fin}^V$ and $\sigma, \tau\in F(V)$
	\begin{enumerate}
		\item $\forall a, b \in A.\ s(\sigma, a \monop b) = s(\sigma, a) \monop s(\sigma, b)$,
        \item $\forall a \in A.\ \sigma \mid_{sv(a)} = \tau \mid_{sv(a)} \implies s(\sigma, a) 
        = s(\tau, a)$,
        \item if $\sigma \mid_{\sigma^{c}(X)}$ is injective then $\exists(X, s(\sigma, a)) = 
        s(\sigma, \exists(\sigma^{c}(X), a))$.				
    \end{enumerate}
\end{definition}

%Clearly item $3$ always holds for an empty $X$.
%
We usually denote $s(\tau,a)$ as $s_\tau a$.
Now, being an action implies that $s_\iota a = a$, and 
together with item $2$ it implies that $s_{\tau} \monid = \monid$.
A polyadic operator offers enough structure for modelling variable substitution. 
%
In the following, we fix a polyadic operator $s$ for $\exists$.

\begin{remark}
The laws are directly adapted from~\cite{sagi2013}, with the exception of $2$, which 
is stated as for a finite non-empty $X \subseteq V$ and $a \in A$
	\begin{itemize}
          \item[\emph{2'}.] $\sigma \mid_{V \setminus X} = \tau \mid_{V \setminus X}
		         \implies \forall a\in A.\ s(\sigma, \exists (X, a)) = s(\tau, \exists (X, a))$.
        \end{itemize}
However, the two formulations are equivalent. Indeed, note that
$\sigma \mid_{V \setminus X} = \tau \mid_{V \setminus X}$ implies 
$\sigma \mid_{sv(a) \setminus X} = \tau \mid_{sv(a) \setminus X}$, 
which in turn implies that 
$\sigma \mid_{\exists (X, a)} = \tau \mid_{\exists (X, a)}$, and 
assuming item $2$ the result follows.
%
For the vice-versa, first of all note that 
$\sigma \mid_{V \setminus X} = \tau \mid_{V \setminus X}$
coincides with $\sigma \mid_{Y \setminus X} = \tau \mid_{Y \setminus X}$
for $Y = sv(\sigma) \cup sv(\tau) \subseteq V$, and that $Y$ is finite
since both $\sigma$ and $\tau$ are finitely supported.
Now, $\sigma \mid_{sv(a)} = \tau \mid_{sv(a)}$ implies that 
$\sigma \mid_{Y \setminus (Y \setminus sv(a))} = \tau \mid_{Y \setminus (Y \setminus sv(a))}$,
thus by $2a$ we have 
$s(\sigma, \exists (Y \setminus sv(a), a)) = s(\tau, \exists (Y \setminus sv(a), a))$.
Since by definition we have $\exists (Y \setminus sv(a), a)) = a$, the result follows.
\end{remark}

%\begin{remark}
%Note also that $\sigma(\sigma^{c}(X)) \subseteq X$, so, when restricted to singleton, we have that item %$3$ in Definition~\ref{def:poly} is equivalent to
%\begin{itemize}
%          \item[\emph{3'}.] $\forall a\in A.\ \sigma^{c}(x) = \{y\} \implies \exists_x s_{\sigma} a =  %s_\sigma \exists_y a$,
%          \item[\emph{3''}.] $\forall a\in A.\ \sigma^{c}(x) = \emptyset \implies \exists_x s_{\sigma} %a =  s_\sigma a$.
%\end{itemize}
%\end{remark}

%\noindent As we did for $\exists$, we define the support of $\sigma$ as follows:
%\begin{itemize}
%\item $sv(\sigma) = \bigcap X \subseteq V \mid \sigma(X) \neq X$
%\end{itemize}

\subsection{Properties of Polyadic Operators}
\label{propo}
In this section we just show some facts concerning
polyadic operators: they ensure that indeed these operators 
suitably axiomatise substitutions. 
%
More precisely, we consider a few simple properties that mimic those holding
for substitutions modelled via diagonals, as considered e.g. in~\cite[Lemma~2 and Lemma~3]{jlamp17}.

\begin{definition}[inverse functions]
	\label{def:inverse}
	Let $\sigma \in F(V)$ be \emph{invertible}, i.e., such that $\sigma \mid_{sv(\sigma)}$ is injective.
	Its \emph{inverse} is defined as
	$$\sigma^{-1}(y) = \bigg \{\begin{array}{rl}
	x & \mathit{if} \ y = \sigma(x) \ and \ x \in sv(\sigma) \\
		y & \ otherwise
	\end{array}$$
	%i.e., $\{^y/_x\}(z) = z$ for all $z \neq x$.
	%
Its \emph{injective lifting} is defined as
	$$\sigma_l(y) = \bigg \{\begin{array}{ll}
	\sigma(y) & if \ y \in sv(\sigma) \\
	\sigma^{-1}(y) & \ otherwise
	\end{array}$$
\end{definition}

In other terms, note that an element $y \in \sigma(sv(\sigma))$ can be the image along $\sigma$ of at most two elements: 
should this be the case, one of them is the element itself 
and the other belongs to $sv(\sigma)$.
When defining the inverse, we give precedence to the element in $sv(\sigma)$.
%
Instead, the injective lifting is indeed an injective substitution.

%Polyadic substitution behaves correctly with respect to $\exists$. 
\begin{lemma} \label{lemma:Inv0}
Let $\sigma \in F(V)$ be invertible. Then it holds
\begin{itemize}
\item $sv(\sigma_l) = \sigma(sv(\sigma)) \cup sv(\sigma) = sv(\sigma_l^{-1})$,
\item $sv(\sigma^{-1}) = \sigma(sv(\sigma))$,
\item $sv(\sigma^{-1} \circ \sigma) = \sigma(sv(\sigma)) \setminus sv(\sigma)$,
\item $sv(\sigma \circ \sigma^{-1}) = sv(\sigma) \setminus \sigma(sv(\sigma))$.
\end{itemize}
\end{lemma}

The set-theoretical proofs are immediate and are omitted. Lemma~\ref{lemmaSubs0} helps to ensure that polyadic substitution behaves correctly with respect to $\exists$. 
We recall that the properties below mirror 
those obtained for substitutions via diagonal operators~\cite{jlamp17}.
%\marginpar{leave if needed}

\comment{
\begin{remark}
With respect to the notion of diagonal
operators~\cite{xxx}\todo{Manca citazione}, as e.g. adopted in~\cite{jlamp17}, in the present context they are not defined, since in our RePOs we do not have the $\top$ elements.

DIRE DI PIU'
\end{remark}
}

\begin{lemma}
	\label{lemmaSubs0}
	Let $\sigma \in F(V)$ invertible, $a \in A$, and $W \subseteq V$ finite. Then it holds
	\begin{enumerate}
		\item $s_{\sigma} \exists_{sv(\sigma)} a = \exists_{sv(\sigma)} a$
		\item if $\sigma(sv(\sigma)) \cap sv(a) = \emptyset$ then 
		$\exists_{sv(\sigma)} a = \exists_{\sigma(sv(\sigma))} s_{\sigma} a$
		\item if $W \cap (sv(\sigma) \cup \sigma(sv(\sigma))) = \emptyset$ then 
		$s_{\sigma} \exists_W a = \exists_W s_{\sigma} a$
	\end{enumerate}
\end{lemma}
\begin{proof}
Proofs are immediate.
As for item $1$, it is a consequence of $\sigma \mid_{V \setminus sv(\sigma)} = id \mid_{V \setminus sv(\sigma)}$.

Concerning now item $3$, since $W$ satisfies $W \cap sv(\sigma) = \emptyset$ then $\sigma(W) = W$,
and since additionally $W \cap \sigma(sv(\sigma)) = \emptyset$ it also follows that $\sigma^{c}(W) = W$. Thus
we have that 
$\exists_W s_{\sigma} a = \exists_{\sigma(W)} s_{\sigma} a = s_{\sigma} \exists_{\sigma^{c}(W)} a = s_{\sigma} \exists_W a$,
where the intermediate equality holds by item 3 of Lemma~\ref{lemma:Inv0}.

Let us finally move to item $2$, and let us consider the lifting $\sigma_l$. This can be less parsimoniously described as
%
%$\sigma'$ defined as follows:
$$\sigma_l(y) = \bigg \{\begin{array}{ll}
	\sigma(y) & \ \mathit{if} \ y \in sv(\sigma) \\
	\sigma^{-1}(y) & \ \mathit{if} \ y \in \sigma(sv(\sigma)) \setminus sv(\sigma) \\
	y & \ otherwise
	\end{array}$$
%Then $\sigma'$ is an injective substitution and switches the variables in $sv(\sigma)$ and $\sigma(sv(\sigma))$ in some way. 
By the hypothesis $\sigma(sv(\sigma)) \cap sv(a) = \emptyset$ we have that $\sigma \mid_{sv(a)} = \sigma_l \mid_{sv(a)}$,
%
hence it holds $\exists_{sv(\sigma)} a = s_{\sigma} \exists_{sv(\sigma)} a = s_{\sigma_l} \exists_{sv(\sigma)} a$.
%
Now note that $(\sigma_l)^{c}(\sigma(sv(\sigma))) = sv(\sigma)$, for $(\sigma_l)^{c}$ the set-theoretical inverse of $\sigma_l$, 
thus again by item $3$ of Definition~\ref{def:poly} we have that $s_{\sigma_l} \exists_{sv(\sigma)} a = \exists_{\sigma(sv(\sigma))} s_{\sigma_l} a = \exists_{\sigma(sv(\sigma))} s_{\sigma} a$.
%As for $2$, let $\tau$ such that $\hat{\tau} \mid_{sv(\hat{\tau})}: Y \rightarrow V$ is bijective, $Im(\hat{\tau} \mid_{sv(\hat{\tau})}) = X$, $\hat{\tau} \mid_{V \setminus sv(\hat{\tau})} = id \mid_{V \setminus sv(\hat{\tau})}$ and let $\hat{\sigma}'$ defined as follows:
%	\begin{itemize}
%		\item $\hat{\sigma}'(y) = \hat{\sigma}(y)$ if $y \not \in Y$
%		\item $\hat{\sigma}'(y) = \hat{\tau}(y)$ otherwise
%	\end{itemize}
%$\hat{\sigma}'$ switches all the variables in $sv(\hat{\sigma})$ and $sv(\hat{\tau})$ in some way. Then we have $s_{\hat{\sigma}} \exists_Y a = s_{\hat{\sigma}'} \exists_Y a$ and $\exists_Y s_{\hat{\sigma}'} \exists_Y a = s_{\hat{\sigma}'} \exists_X \exists_Y a = \exists_X a$
\qed
\end{proof}

%\begin{proof}
%	The proofs are immediate. Consider for instance the most difficult item $3$.
%	If $x=y$ the proof is over. Now, since $w \not \in \{x, y\}$ we have 
%	by definition that
%	$\delta_{x,y} = \exists_w(\delta_{x,w} \monop \delta_{w,y})$.
%	Again by definition $b [^y/_x] = \exists_x(\delta_{x,y} \monop b)$, so that
%	$\exists_w (a [^y/_x]) =  \exists_w \exists_x(\delta_{x,y} \monop a) = 
%	\exists_x \exists_w(\delta_{x,y} \monop a) = 
%	\exists_x (\delta_{x,y} \monop \exists_w a) = 
%	(\exists_w a) [^y/_x]$.
%\end{proof}

Finally, we rephrase some further laws of the crisp case 
%It is easy to prove that the following laws hold 
(see~\cite[p.140]{pippo}).

\begin{lemma}
	\label{lemmaSubs}
	Let $\sigma \in F(V)$ be invertible. Then it holds
	\begin{enumerate}
		\item $\forall a\in A.\ (sv(\sigma) \setminus  \sigma(sv(\sigma))) \cap sv(s_\sigma a) = \emptyset$.
		\item $\forall a\in A.\ (\sigma(sv(\sigma)) \setminus sv(\sigma)) \cap sv(a) = \emptyset \implies s_{\sigma^{-1}} s_{\sigma} a = a$,
		%\item $s_{\sigma} a = a \iff sv(a) \cap sv(\sigma) = \emptyset$
	\end{enumerate}
\end{lemma}

\begin{proof}
	As for item $1$, note that $sv(s_{\sigma} a) = \sigma(sv(a))$. Let $Z = sv(\sigma) \cap sv(a)$: 
	then $\sigma(Z) \subseteq \sigma(sv(\sigma))$ and $\sigma \mid_{sv(a) \setminus Z} = \iota \mid_{sv(a) \setminus Z}$, which implies $(sv(a) \setminus Z) \cap sv(\sigma) = \emptyset$.
	Since $\sigma(Z) \subseteq \sigma(sv(\sigma))$, it holds $(sv(\sigma) \setminus \sigma(sv(\sigma)) \cap \sigma(sv(a)) = (sv(\sigma) \setminus \sigma(sv(\sigma)) \cap sv(s_{\sigma} a) = \emptyset$.

	As for item $2$, by definition it holds $s_{\sigma^{-1}} s_{\sigma} a = s_{\sigma^{-1} \circ \sigma} a$. 
	Now, item $3$ of Lemma~\ref{lemma:Inv0} implies that $sv(\sigma^{-1} \circ \sigma) = \sigma(sv(\sigma)) \setminus sv(\sigma)$, 
	and since $\sigma(sv(\sigma)) \cap sv(a) = \emptyset$ it holds $(\sigma^{-1} \circ \sigma) \mid _{sv(a)} = \iota \mid _{sv(a)}$.
	The result then follows by item $2$ of Definition~\ref{def:poly}.	
\qed	
	%Consider now item $3$: note that $a = b \implies \exists_X a = \exists_X b$. Then $s_\sigma a = a \implies \exists_{\sigma(sv(a))} s_\sigma a = \exists_{sv(a)} a \implies s_\sigma \exists_{\sigma^{-1}(sv(a))} a = \exists_{sv(a)} a \implies \sigma^{-1}(sv(a)) = sv(a) \implies sv(\sigma) \cap sv(a) = \emptyset$. \\
	%Questo pero' mi confonde: se $\sigma$ fosse una permutazione varrebbe lo stesso. \\
	%To proove $sv(\sigma) \cap sv(a) \implies s_{\sigma} a = a$, consider the contrapositive of item $2$ in Definition~\ref{def:poly}: then it holds $s_{\sigma} a \not = a \implies \sigma \mid_{sv(a)} \not = \iota \mid_{sv(a)}$, i.e. there exists $X \subseteq sv(a) \not = \emptyset$ such that $\sigma(X) \not = X$, which in turn implies $sv(\sigma) \cap sv(a) \not = \emptyset$.
	%$\hat{\tau} \circ \hat{\sigma} = \hat{\tau}$, then $s_{\hat{\tau} \circ \hat{\sigma}} a = s_{\hat{\tau}} \exists_Y a$. Since $Y = sv(\hat{\tau})$, the result follows from $1$ of Lemma~\ref{lemmaSubs0}.
	%$\{^x/_y\} \mid_{V \setminus\{y\}} = id \mid_{V \setminus\{y\}}$.
	%As for $3$,  note that $\sigma^{-1} (X) = \emptyset$, thus
	%$\exists_X s_{\sigma} a = s_{\sigma} a$ and the result holds.
%	Consider for instance the most difficult item $3$.
%	If $x=y$ the proof is over. Now, since $w \not \in \{x, y\}$ we have 
%	by definition that
%	$\delta_{x,y} = \exists_w(\delta_{x,w} \monop \delta_{w,y})$.
%	Again by definition $b [^y/_x] = \exists_x(\delta_{x,y} \monop b)$, so that
%	$\exists_w (a [^y/_x]) =  \exists_w \exists_x(\delta_{x,y} \monop a) = 
%	\exists_x \exists_w(\delta_{x,y} \monop a) = 
%	\exists_x (\delta_{x,y} \monop \exists_w a) = 
%	(\exists_w a) [^y/_x]$.
\end{proof}

\subsection{Cylindric and Polyadic Operators for Residuated Monoids}
\label{cyre}
Both algebraic structures introduced in the previous section are quite standard,
even if polyadic operators are less-known in the soft-constraints literature:
we tailored their presentation to our needs, and indeed the properties
presented in Section~\ref{propo} appear to be original. It is now time to consider 
the interaction of such structures with residuation. 
%
To this end, in the following we assume that 
$\mathbb{S}$ is a RePO (see Definition~\ref{def:repo}).


\begin{lemma}
Let $X \subseteq V$ be finite. Then it holds
	\begin{itemize}
         \item $\forall a, b \in A.\ \exists_X(a \odiv \exists_X b) \leq \exists_X a \odiv \exists_X b$.
	\end{itemize}
\end{lemma}

\begin{proof}
 \[\exists_X b \otimes (a \odiv \exists_X b) \leq a \implies
   \exists_X(\exists_X b \otimes (a \odiv \exists_X b)) \leq \exists_X a \implies\]
 \[\exists_X b \otimes \exists_X(a \odiv \exists_X b)) \leq \exists_X a \implies
   \exists_X(a \odiv \exists_X b) \leq \exists_X a \odiv \exists_X b\]
   \qed
\end{proof}

\begin{remark}
Looking at the proof above, it is clear that $\exists_x(a \odiv \exists_x b) \leq \exists_x a \odiv \exists_x b$
is actually equivalent to state that
$\exists_x(a \monop \exists_x b) \geq \exists_x a \monop \exists_x b$.
\end{remark}

%\begin{remark}
%\todo{un esempio dove $\odiv$ non distribuisce}
%\end{remark}

Similarly, it is easy to show that it holds $\forall a, b \in A.\ \exists_X(\exists_X a \odiv b) \leq \exists_X a \odiv \exists_X b$. 
%
A similar result relates residuation and polyadic operators.
%the following lemma holds.
%\todo{Mettere motivazione Lemma?}

\begin{lemma}
Let $\sigma,\tau \in F(V)$. Then it holds
\begin{itemize}
\item $\forall a,b \in A.\ s_\sigma (a \odiv b) \leq s_\sigma a \odiv s_\sigma b$.
\end{itemize}
\end{lemma}

%\begin{proof}
%\[ a \otimes (b \odiv a) \leq b \implies \]
%\[ s_\sigma [a \otimes (b \odiv a)] \leq s_\sigma b \implies \]
%\[ s_\sigma a \otimes s_\sigma(b \odiv a) \leq s_\sigma b \implies \]
%\[ s_\sigma (b \odiv a) \leq s_\sigma b \odiv s_\sigma a \]
%\end{proof}

\section{Polyadic Soft Constraints}\label{sec:softconstraints}
\label{subsec:inst} 
In the past sections we mentioned a few ReSLs such as 
the Fuzzy 
%semiring  $\langle [0, 1], \leq, \times, 1 \rangle$ 
%of the $[0, 1]$ interval of real numbers with the usual order and multiplication
%as the monoidal operator
and the Tropical semiring.
%$\langle \mathbb{R}^+ \cup\{+\infty\}, \geq, +, 0 \rangle$
%non-negative reals plus $\infty$ with the inverse order and addition.
%
Building on such examples, in this section we give a main case study: a ReSL 
where the notion of cylindric and polyadic operators can be easily given.
It exploits the notion
of soft constraint: indeed, our proposal follows yet generalises \cite{scc},
whose underlying algebraic structure is the one of absorptive semirings.

\begin{definition}[(soft) constraints]\label{def:softconstraints}
	Let $V$ be a set of variables, $D$ a finite domain of interpretation
	and ${\mathbb S} = \langle A, \leq, \monop, \odiv, \monid \rangle$ a ReSL.
	A \emph{(soft) constraint} $c: (V \rightarrow D) \rightarrow
	A$ is a function associating a value in $A$ with each assignment
	$\eta: V\rightarrow D$ of the variables.
\end{definition}

In this section and in the following one, we denote by $\mathcal{C}$ the set of constraints that can be
built starting from chosen $\mathbb S$, $V$, and $D$. The application of a
constraint function $c:(V \rightarrow D) \rightarrow A$ to a variable
assignment $\eta:V\rightarrow D$ is denoted $c\eta$.  

Even if
a constraint involves all the variables in $V$, it may depend on
the assignment of a finite subset of them, called its support. For
instance, a binary constraint $c$ with $supp(c)=\{x,y\}$ is a function
$c: (V\rightarrow D)\rightarrow A$ that depends only on the
assignment of variables $\{x,y\}\subseteq V$, meaning that two
assignments $\eta_1, \eta_2: V \rightarrow D$ differing only for the
image of variables $z \not \in \{x,y\}$ coincide (i.e., $c\eta_1 =
c\eta_2$).
%
The support corresponds to the classical notion of scope of a
constraint.  We often refer to a constraint with support $X$ as $c_X$.
Moreover, an assignment over a support $X$ of cardinality $k$ is concisely
represented by a tuple $t$ in $D^k$, and we often write $c_X(t)$
instead of $c_X\eta$.

\smallskip
The set of constraints forms a ReSL, with the structure
lifted from ${\mathbb S}$.

\begin{lemma}[the ReSL of constraints]\label{prop:soft}
	The ReSL of constraints $\mathbb C$ is
	defined as the tuple $\langle {\mathcal C}, \leq, \monop, \odiv, \monid \rangle$ such that
	
	\begin{itemize}
		\item $c_1 \leq c_2$ if $c_1\eta\leq c_2\eta$ for all $\eta: V \rightarrow D$,
		\item $(c_1\monop c_2)\eta = c_1\eta\monop c_2\eta$, %for $c_1, c_2\ \in {\mathcal C}$
		\item $(c_1\odiv c_2)\eta = c_1\eta\odiv c_2\eta$, %for $c_1, c_2\ \in {\mathcal C}$
		\item $\monid \eta = \monid$.
	\end{itemize}
\end{lemma}


Combining constraints by the $\monop$ operator
means building a new constraint whose support involves at most
the variables of the original ones. The resulting constraint  associates with
each tuple of domain values for such variables the element
that is obtained by multiplying  those associated by the
original constraints to the appropriate sub-tuples.
%
%Residuation works as expected (i.e., $(c_1\odiv c_2)\eta = c_1\eta\odiv c_2\eta$),
%and 
%Also, the bottom is the constant function mapping all $\eta$ to $\bot$.

%\begin{example}[A simple CLIM]\label{execlim}
%Let us consider a CLIM $\mathbb S$, 
%and as $D$ a finite subset of the elements of the CLIM.
%A polynomial with variables in $V$ 
%and elements of the CLIM as coefficients
%such as $ux \, \hat{+} \, vy \, \hat{+} \, z$
%can be interpreted as the soft constraint associating 
%with a function $\eta: V \rightarrow D$ the value 
%$\bigvee \{u \monop \eta(x), v \monop \eta(y), z \}$.
%The composition of such constraints is straightforward, while 
%the ordering might not be the one induced by the coefficients, 
%due to the presence of constants.
%
%More precisely, let us consider the CLIM of non-negative reals and
%the polynomials $2x \, \hat{+} \, 1$ and $x \, \hat{+} \, 6$
%and let us assume $D = \{1, 2, 3\}$.
%The composition of such constraints is actually given just by coefficient 
%addition, so that
%$(2x \, \hat{+} \, 1) \monop (x \, \hat{+} \, 6) = 
%(3x \, \hat{+} \, 7)$.
%However, note that $2x \, \hat{+} \, 1 \leq x \, \hat{+} \, 6$.
%
%
%Similarly for residuation, which is just bounded subtraction of coefficients.
%Since $2x \, \hat{+} \, 1 \leq x \, \hat{+} \, 6$,
%by construction ($2x \, \hat{+} \, 1) \odiv (x \, \hat{+} \, 6)$ is the bottom constraint,
%mapping all variables to $0$.
%Instead, $(x \, \hat{+} \, 6) \odiv (2x \, \hat{+} 1)$ could be described as $\hat{-}x \, \hat{+} \, 5$,
%even if
%the latter falls outside of the polynomials we considered since it has a negative coefficient:
%it suffices to assume that if the actual result of the evaluation of the polynomial is negative 
%then it is put to $0$.
%
%%
%If $D$ is not the singleton, the support of a polynomial is precisely the set of variables occurring in it.
%\end{example}

%The ReSL of constraints also enjoys the cylindric properties, as shown by
%the result below (for cylindric operators and diagonals in the idempotent case, see~\cite{scc}).

\begin{lemma}[Cylindric and polyadic operators for (soft) constraints]
	The ReSL of constraints $\mathbb{C}$ admits cylindric and polyadic operators, defined as
	\begin{itemize}
		\item  $(\exists_X c) \eta = \bigvee \{c \rho \mid \eta\mid_{V \setminus X} = 
		\rho\mid_{V \setminus X}\}$ for all $c \in {\mathcal C}, X \subseteq V$
		%\item if $\sigma$ is an injective substitution, then $(s_{\sigma}c)\eta = c(\sigma \circ \eta)$ 
		%for all $c \in \mathcal{C}$
		\item  $(s_\sigma c) \eta = c (\eta \circ \sigma)$ for all $c \in {\mathcal C}, \sigma \in F(V)$	
%		\item $\delta_{x,y}\eta = \left\{
%		\begin{array}{rcl} \bot & & \text{if } \eta(x) = \eta(y); \\
%		\top & & \text{otherwise.}
%		\end{array} \right.$ for all $x, y \in V$
	\end{itemize}
\end{lemma}

Hiding means eliminating variables from the support:
$supp(\exists_X c) \subseteq supp({c}) \setminus X$.\footnote{The operator
	is called \emph{projection} in the soft framework,
	and $\exists_X c$ is denoted $c\Downarrow_{V\setminus X}$.}

\begin{proof}
%Let us consider a finite set $X$ and a constraint $c$. Recall that since $supp(c)$ is finite,
%$c$ can be considered as a function $D^k \rightarrow A$ for $k = \# supp(c)$.
%
%Thus $(\exists_X c) \eta$ just boils down to consider the LUB of $\# supp(c) \setminus X$ 
%sets of $k$-tuples, and t
The properties of the pomonoid action (see Definition~\ref{pomo})
are easily shown to hold for both operators. 
%
As for the cylindric laws (see Definition~\ref{cyli}), first note that the set of functions 
$\rho$ such that $\eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}$ is actually finite.
Thus, we have that 
\begin{eqnarray*}
(\exists_X (c \otimes \exists_X d)) \eta & = & \bigvee_\rho \{(c \otimes \exists_X d) \rho \mid \eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}\}\\
& = & \bigvee_\rho \{c\rho \otimes (\exists_X d) \rho \mid \eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}\} \\
& = & \bigvee_\rho \{c\rho \otimes  (\bigvee_\xi \{d \xi \mid \rho\mid_{V \setminus X} = \xi\mid_{V \setminus X}\}) \mid \eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}\} \\
& = & \bigvee_\rho \{c\rho \mid \eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}\} \otimes \bigvee_\xi \{d \xi \mid \eta\mid_{V \setminus X} = \xi\mid_{V \setminus X}\} \\
& = & (\exists_X c) \eta \otimes (\exists_X d) \eta
\end{eqnarray*}

% = 
% =\]
%= \]
% =\]
% =
%(\exists_X c) \eta \otimes (\exists_X d) \eta \]
%%\[ (\exists_X d) \rho = \bigvee \{d \xi \mid \rho\mid_{V \setminus X} = \xi\mid_{V \setminus X}\}\]

Let us now move to the polyadic laws (see Definition~\ref{def:poly}).We just consider the third item, 
and we assume that $\sigma \mid_{\sigma^c(X)}$ is injective, thus
\begin{eqnarray*}
(\exists_X s_\sigma c) \eta & = &\bigvee_\rho \{(s_\sigma c) \rho \mid \eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}\} = \bigvee_\rho \{c (\rho \circ \sigma) \mid \eta\mid_{V \setminus X} =   \rho\mid_{V \setminus X}\} \\ 
& = & \bigvee_\xi \{c\xi \mid (\eta \circ \sigma)\mid_{V \setminus \sigma^{c}(X)}  =  \xi\mid_{V \setminus \sigma^{c}(X)}\} \\
& = & (\exists_{\sigma^c(X)} c) (\eta \circ \sigma) = (s_\sigma \exists_{\sigma^c(X)} c) \eta
\end{eqnarray*}


%  \bigvee \{c (\rho \circ \sigma) \mid (\eta\circ \sigma)\mid_{V \setminus \sigma^{c}(X)} = (\rho\circ \sigma)\mid_{V \setminus \sigma^{c}(X)}\}=^{*}\]
\noindent
where it always holds that $\eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}$ implies $(\eta\circ \sigma)\mid_{V \setminus \sigma^{c}(X)} = (\rho\circ \sigma)\mid_{V \setminus \sigma^{c}(X)}$,
while since $\sigma \mid_{\sigma^c(X)}$ is injective we have that
a $\xi$ satisfying $(\eta \circ \sigma)\mid_{V \setminus \sigma^{c}(X)} = \xi\mid_{V \setminus \sigma^{c}(X)}$ can be decomposed as $\rho\circ \sigma$
for a $\rho$ such that $\eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}$
(otherwise, it could happen that for some $\{x, y\} \subseteq \sigma^c(X)$ we have that $\sigma(x) =\sigma(y)$ and 
$\xi(x) \neq \xi(y)$).
\qed
\end{proof}

%
%Finally, the diagonal element $\delta_{x,y}$ has support $\{x, y\}$ for 
%$x \neq y$, while the support for $\delta_{x,x}$ is $\emptyset$. 


\comment{
Note also that the diagonal elements are not guaranteed to be $\monop$-compact,
even if they have finite support, since $\top$ is not necessarily so.
%
To this end, we close the section by adding the simple result below to the soft constraint lore.

\begin{proposition}
	Let $c \in \mathbb{C}$ be a constraint. It is $\monop$-compact if and only if it has finite support and 
	$c\eta$ is $\monop$-compact for all $\eta$.
\end{proposition}
}

\section{Deterministic Soft CCP}\label{sec:detSCCP}
This section introduces our (meta-)language.
We fix a set of variables $V$, ranged over by $x$, $y$, $\ldots$ , and 
an invertible CLIM $\mathbb S = \langle {\mathcal C}, \leq, \otimes\rangle$, which is 
cylindric over $V$ and whose compact elements
are ranged over by $c$, $d$, $\ldots$.

\begin{definition}[Agents]%
The set $\mathcal{A}$ of all agents, %which is
parametric with respect to a set $\mathcal{P}$ of (unary) procedure declarations $p(x)$,
is given by the following grammar
\[ A \Coloneqq \: \: \mathit{\ostop} \mid \textit{\tell}(c)  \mid \textit{\ask}(c) \rightarrow A \mid A \parallel A \mid \exists_x A \mid %Z \mid \mu_Z A
p(x).\]  
\end{definition}

We denote by $fv(A)$ the set of free variables of an agent, defined in the expected way 
by structural induction, assuming that $fv(\tell(c)) = sv(c)$ and
 $fv(\ask(c) \rightarrow A) = sv(c) \cup fv(A)$.
 %
 In the following, we restrict our attention to 
 procedure declarations $p(x) = A$ such that $fv(A) = \{x\}$.

%
%
%%Given a soft constraint system $S_C=\langle \C, \otimes,\bot,\top ,
%%\exists_x, d_{xy}\rangle$ as defined in
%%Section~\ref{sec:softconstraints}, the syntax
%%of  deterministic \SCCP agents is defined as
%
%
%\def\odivv{\; {\ominus\hspace{-4pt} \div} \;}
%\def\odivvv{\; {\ominus\hspace{-6pt} \div} \;}
%\begin{table}
%%\footnotesize
%\begin{center}
%%P \Coloneqq \: \: F.A \; \; \; \; \; \; \; \;
%%F \Coloneqq \: \: p(\hat{x})::A \mid F.F \; \; \; \; \; \; \; \;
%$A \Coloneqq \: \: \mathit{\ostop} \mid \textit{\tell}(c)  \mid \textit{\ask}(c) \rightarrow A \mid A \parallel A \mid \exists_x A \mid %Z \mid \mu_Z A$
%p(x)$
%\end{center}
%%\normalsize
%\caption{The syntax of deterministic soft CCP}
%\label{syntax}
%\end{table}
%
%In Tab.~\ref{syntax} we recall the deterministic fragment of soft CCP,
%with respect to the standard proposal, we replaced the procedure call with the
%simpler to handle recursion operator $\mu_Z$.
%%\marginpar{A che servono F e P?}
%%
%Let $\mathcal{A}$ be the set of all agents, which is
%parametric with respect to a set $\mathcal{P}$ of (unary) procedure declarations 
%$p(x) = A$ such that $fv(A) = \{x\}.$\footnote{The set of free variables of an agent is defined in the
 %expected way by structural induction, assuming that $fv(\tell(c)) = sv(c)$ and $fv(\ask(c) 
 %\rightarrow A) = sv(c) \cup fv(A)$.}
%
%$\mathcal{P}$ is the class of programs, $\mathcal{F}$ is the class of sequences of procedure
%declarations,
%$\mathcal{A}$ is the set of agents and
%$\mathcal{Z} = \{Z, Z_1, Z_2 \ldots\}$ is the set of recursion variables, 
%$c \in \C^\otimes$ with $sv(c) \in V$.
%
%, and $\hat{x}$ is a tuple of variables in $Var$ passed in a procedure call.
%
%In $p(\hat{x}) :: A$ we assume that the variables in
%$\mathit{vars}(A)$, i.e. the set of variables occurring either as parameters of procedure calls or belonging
%to the support of
%the constraints in agent $A$, also occur
%among $\hat{x}$.
%\footnote{Note that, with respect to the standard proposals, we require only for the
%$\textit{ask}$ operator to have a compact constraint, while the $\textit{tell}$ ranges over all constraints.
%Intuitively, we allow to require to the store the removal of certain constraint, while compactness allow
%for obtaining a simpler relation when checking the entailment of a constraint.}

We now move to consider the reduction semantics of our language.

\begin{definition}[Substitutions]
Let $[^y/_x] \in F(V)$, defined as: 
\[ [^y/_x](w) = 
		\begin{cases} 
			y & \text{if $w = x$} \\
            w & \text{otherwise}
        \end{cases} \]
The substitution operator $s_{[^y/_x]}: \mathcal{A} \rarrow \mathcal{A}$ on agents is defined by structural induction as 

\begin{itemize}
	\item $s_{[^y/_x]} \ostop = \ostop$
	\item $s_{[^y/_x]}\tell(c) = \tell(s_{[^y/_x]}c)$
	\item $s_{[^y/_x]} p(w) =  p([^y/_x](w))$
	\item $s_{[^y/_x]} (\ask(c) \rightarrow A) = \ask(s_{[^y/_x]}(c)) \rightarrow s_{[^y/_x]} A$
	\item $s_{[^y/_x]} (\exists_w A)  = 
		\begin{cases} 
			\exists_w A & \text{if $w = x$} \\
            \exists_z (s_{[^z/_y]} s_{[^y/_x]} A) & \text{for z fresh if $w = y$} \\
            \exists_x (s_{[^y/_x]} A) & \text{otherwise}
        \end{cases}$
\item $s_{[^y/_x]}(A_1 \parallel A_2)  = (s_{[^y/_x]} A_1 \parallel s_{[^y/_x]} A_2)$
\end{itemize}
\end{definition}

%The substitution on compact elements is the one given in Definition~\ref{def:sub}: thanks to Lemma~\ref{lemmaSubs0}, 
%the choice of the intermediate variable is immaterial.
% NO
% $A[^y/_z][^z/_x] = A[^y/_x]$, since each syntactical substitution in $A$ involves all the variables with the same name.



\begin{definition}[Reductions]\label{def:reductions}
Let $\Gamma = {\mathcal A} \times \C^{\otimes}$ be the set of \emph{configurations}.
The \emph{direct reduction semantics} for SCCP is the pair 
$\langle \Gamma,  \mapsto \rangle$
such that $\mapsto \, \, \subseteq \, \,\Gamma \times   \Gamma$ is the family 
 of binary relations indexed over sets of variables,
%$2^V$,
%between them, 
i.e., $\mapsto = \bigcup_{\Delta \subseteq V} \mapsto_\Delta$ and 
$\mapsto_\Delta \, \, \subseteq \, \,\Gamma \times \Gamma$, obtained by the rules in 
Table~\ref{fig:operational}.

The \emph{reduction semantics} for SCCP is the pair 
$\langle \Gamma,  \rightarrow \rangle$
such that $\rightarrow \, \, \subseteq \, \,\Gamma \times   \Gamma$ is the family 
 of binary relations indexed over sets of variables,
%$2^V$,
%between them, 
i.e., $\rightarrow = \bigcup_{\Delta \subseteq V} \rarrow_\Delta$ and 
$\rarrow_\Delta \, \, \subseteq \, \,\Gamma \times \Gamma$, obtained by the rules in 
Table~\ref{fig:operational} and Table~\ref{fig:operational2}.
\end{definition}

%\vspace{-.25cm}
\def\odiv{\; {\ominus\hspace{-6pt} \div} \;}
\def\odivvv{\; {\ominus\hspace{-6pt} \div} \;}

\begin{table}  %\hfil5
  %\scalebox{0.9}{
   \begin{center}
   \begin{tabular}{llll} 
   %
   \mbox{\bf A1}& $\frac{\displaystyle sv(\sigma) \cup sv(c) \subseteq \Delta } {\displaystyle \langle \hbox{\tell}(c), \sigma \rangle \mapsto_\Delta  \langle \hbox{\ostop},
                                               \sigma \otimes c\rangle}$
   \ \ \ & \bf{Tell}&
  \\ 
  &\mbox{   }&\mbox{   } &\mbox{   }
  \\
  \mbox{\bf A2}& $\frac {\displaystyle sv(\sigma) \cup sv(c) \cup fv(A) \subseteq \Delta \wedge c \leq \sigma}{\displaystyle
  	\begin{array}{l} \langle \hbox{\ask}(c) \rightarrow A, \sigma \rangle \mapsto_\Delta \langle A, \sigma \rangle   	\end{array}}$
    \ \ \ & \bf{Ask}&
    \\
    &\mbox{   }&\mbox{   }&
    \\
  \mbox{\bf A3}& $\frac {\displaystyle sv(\sigma) \cup \{y\} \subseteq \Delta \wedge \displaystyle p(x) = A \in \mathcal{P} }
  {\displaystyle\langle p(y),\sigma\rangle \mapsto_\Delta \langle s_{[^y/_x]} A, \sigma \rangle}$ 
  &\bf{Rec}&
    \\
   &\mbox{   }&\mbox{   }&
  \\
    \mbox{\bf A4}& $\frac {\displaystyle sv(\sigma) \cup fv(\exists_x A) \subseteq \Delta 
    \wedge w \not \in \Delta }
    {\displaystyle\langle \exists_x A,\sigma\rangle \mapsto_\Delta \langle s_{[^w/_x]} A, \sigma\rangle}$
    &\bf{Hide}&
  \end{tabular}
  \end{center}
\caption{Axioms of the reduction semantics for SCCP.}
\label{fig:operational}
\end{table}

\begin{table}  %\hfil5
  %\scalebox{0.9}{
   \begin{center}
   \begin{tabular}{llll} 
   %
  \mbox{\bf R1}& $\frac {\displaystyle \langle A,\sigma \rangle \rarrow_\Delta \langle A', \sigma' \rangle
  \wedge fv(B) \subseteq \Delta} 
  {\displaystyle \begin{array}{l}
                          \langle A\parallel B, \sigma \rangle \rarrow_\Delta \langle A'\parallel B, \sigma' \rangle
                          \end{array}}$ 
    & \bf{Par1}&
  \\
  & \mbox{   }&\mbox{   }&
  \\
    \mbox{\bf R2}& $\frac {\displaystyle \langle A,\sigma \rangle \rarrow_\Delta \langle A', \sigma'   \rangle
    	\wedge fv(B) \subseteq \Delta} 
    {\displaystyle 
    	\begin{array}{l} \langle B\parallel A, \sigma \rangle \rarrow_\Delta \langle B\parallel A', \sigma' \rangle
    	\end{array}}$& \bf{Par2}&
  \end{tabular}
  \end{center}
\caption{Contextual rules of the reduction semantics for SCCP.}
\label{fig:operational2}
\end{table}

\def\odiv{\, {\ominus\hspace{-7.8pt} \div} \,}
\def\odivvv{\; {\ominus\hspace{-4.7pt} \div} \;}


The split distinguishes between axioms and rules guaranteeing the closure with respect to the parallel operator. Indeed, rules {\bf  R1}  and {\bf  R2} model the interleaving of two agents in parallel.
%
%
In {\bf A1} a constraint $c$ is added to the store $\sigma$.
%, which in the next step will be $\sigma \otimes c$.
%
{\bf A2} checks if $c$ is entailed by  $\sigma$: if not, the computation is blocked.
% until this condition holds, and then continuation $A$ is executed.
%
%provides the standard unfolding step for the recursion operator: the mechanisms of variable.
%substitution and scope are defined as usual.
%
%Rules {\bf  R3}  and {\bf  R4} model the interleaving of two agents in parallel.
%% symmetric rules (on agent $B$) are not shown in Fig.~\ref{fig:operational}.
%\marginpar{Either $\exists_x \ostop = \ostop$ is missing or R4 is basically useless}
%
Axiom {\bf A3} replaces a procedure identifier with the associated body, renaming the formal parameter with the actual one:
%$A[^y/_x]$ stands for the agent obtained by replacing all the occurrences of $x$ with $y$.
%
Axiom {\bf A4} hides the variable $x$ occurring in $A$, replacing it  
with a globally fresh variable,
as ensured by $w \not \in \Delta$.
The latter is more general than just requiring that 
$w \not \in fv(\exists_x A) \cup sv(\sigma)$, since
$\langle B, \rho \rangle   \rarrow_\Delta$ implies that 
$fv(B) \cup sv(\rho) \subseteq \Delta$.\footnote{Our rule is  reminiscent of 
$(8)$ in~\cite[p.~342]{popl91}.}
%
%
%(as $(9)$ in~\cite{popl91}), assuming a set of variables $Var_{\mathcal{P}}$
%(one for each procedure definition) that cannot occurr either in the support nor in the syntax of any agent.
%
%\marginpar{R5 may add non-determinsm!!}
%\marginpar{R5 is much more difficult now: the problem was in the superscript $\sigma''$ for non-idempotent CLIMs}
%Finally, rule {\bf R6} calls a procedure $p(\hat{x})$ by passing the (global) parameters $\hat{y}$:
%%$d_{\hat{x},\hat{y}}$ is a shorthand for the composition of the $d_{x_i,y_i}$'s.
%$A[\hat{y}/\hat{x}]$ is the pairwise renaming in $A$ of variables in  $\hat{y}$ with variables in $\hat{x}$.
%\marginpar{The use of $d_{x,y}$ for R6 would be nicer, but maybe problematic (compactness)}
%Finally, rule {\bf R6} provides the standard unfolding step for the recursion operator: the mechanisms of variable
%substitution and scope are defined as usual.

%\smallskip
Let $\gamma = \langle A, \sigma \rangle$ be a configuration.
%
We denote by $fv(\gamma)$ the set $fv(A) \cup sv(\sigma)$ and by
$\gamma[^z/_w]$ the component-wise application of substitution $[^z/_w]$.

\begin{lemma}[On monotonicity]
\label{mono}
Let $\langle A, \sigma \rangle \rightarrow_\Delta \langle B, \sigma' \rangle$ be a reduction. 
Then
\begin{enumerate}
\item $sv(\sigma') \subseteq sv(\sigma)\cup fv(A) \subseteq \Delta$;
\item $\sigma \leq \sigma'$;
\item $\langle A, \sigma \rangle \rightarrow_{\Delta'} \langle B, \sigma' \rangle$
         for all $\Delta'. sv(\sigma)\cup fv(A) \subseteq \Delta' \wedge fv(B) \cap \Delta' \subseteq fv(A)$;
\item $\langle A, \sigma \otimes \rho \rangle \rightarrow_\Delta \langle B, \sigma' \otimes \rho \rangle$
         for all $\rho \in  \C^\otimes. sv(\rho) \subseteq \Delta$. 
\end{enumerate}
 \end{lemma}
 
 All statements are straightforward. 
%
%\begin{lemma}[Mono]\label{mono}
%Let $\langle A, \sigma \rangle \rightarrow_\Delta \langle B, \sigma' \rangle$
%be a reduction. Then, $\sigma \leq \sigma'$ and $sv(\sigma') \subseteq \Delta$.
%\end{lemma}
%
As for item 1, by construction $sv(\sigma)\cup fv(A) \subseteq \Delta$: since 
only rule {\bf A1} can modify the store
and $sv(\sigma \otimes c) \subseteq sv(\sigma) \cup sv(c)$, then the statement holds.
Similarly for item 2, since $\sigma \leq \sigma \otimes c$.
Item 3 is again true by construction. 
As for item 4, it suffices to also note that 
$\sigma, \rho \in  \C^\otimes$ ensure that $\sigma \otimes \rho \in  \C^\otimes$
and clearly {\bf A2} will still be executable. 
%%The difficult case is  {\bf  R7}, 
%%which is solved since $\sigma \leq  \sigma_0 \otimes \exists_x \sigma'$ and by monotonicity 
%%of $\exists_x$ and $- \odiv \exists_x \sigma_0$. 
%%
%Note that 
%%$A$ may be an extended agent, and 
%$\sigma$ is not necessarily $\otimes$-compact.

%A simple fact to establish is that if 
%$\langle A, \sigma \rangle \rightarrow \langle \exists_x^{\sigma'} B, \sigma" \rangle$
%is a reduction, then $\exists_x \sigma' \leq \sigma"$.
%More can be said by restraining $A$ and $\sigma$. 
%
%\begin{definition}[extended agents, admissible configurations]
%An extended agent $A \in \mathcal{A}^+$ is either an agent $A \in \mathcal{A}$ or it has the shape 
%$A = A_1 \parallel A_2$ and both $A_i$'s are extended agents or it has the shape 
%$\exists_x^\rho A_0$ and $A_0$ is an extend agent and $\exists_x \rho \in \mathcal{C}^\otimes$.
%
%A configuration $\langle A, \sigma \rangle$ is admissible if $A \in \mathcal{A}^+$ and if its shape is 
%$A = A_1 \parallel A_2$ then both $\langle A_i, \sigma \rangle$ are admissible or if its shape is
%$\exists_x^\rho A_0$ then $\langle A_0, \rho \otimes \exists_x (\sigma \odiv \exists \rho) \rangle$ is admissible.
%\end{definition}

%So, let $\mathcal{A}^+$ denote the set of agents obtained by including 
%the extended operators $\exists_x^{\sigma'} -$ such that $\exists_x\sigma'$ is $\otimes$-compact, and let 
%$\langle A, \sigma \rangle$ be admissible if $A \in \mathcal{A}^+$ and whenever $A = A_0 \parallel \ldots \parallel A_n$ %such that $A_i =\exists_x^{\sigma'} A'_i$ then $\exists \sigma' \leq \sigma$ and $\langle A'_i, \sigma' \otimes \exists_x 
%(\sigma \odiv \exists \sigma') \rangle$ is admissible.

%\begin{lemma}\label{comp}
%Let $\langle A, \sigma \rangle \rightarrow \langle B, \sigma' \rangle$ be
%a reduction. If $\langle A, \sigma \rangle$ is admissible, then $\langle B, \sigma' \rangle$ is so and $\sigma' \odiv \sigma \in \mathcal{C}^\otimes$.
%\end{lemma}
%\begin{proof}
%[TO FINISH]
%We proceed by induction on the length of the proof. 
%The axioms {\bf R2}, {\bf R5}, and {\bf R6} are straightforwardly checked, so, the only one 
%to be verified is if the last inference rule applied 
%%in the $n$-th step 
%is {\bf R7}.
%%
%So, let $\langle \exists^{\sigma'}_x A,
%\sigma \rangle \rrarrow \langle \exists^{\sigma_1}_x B, \sigma_0 \otimes \exists_x \sigma_1\rangle$ with the construction of rule {\bf R7}. By hypothesis, $up = \sigma'' \odiv (\sigma' \otimes \exists_x \sigma_0) =  (\sigma'' \odiv \sigma') \odiv \exists_x \sigma_0 = \sigma_1 \odiv \sigma'$ is $\otimes$-compact. Now, $\sigma_1 \leq up \otimes \sigma'$, so that 
%$\exists_x \sigma_1 \leq \exists_x (up \otimes \sigma')$: by Lemma~\ref{preserve} $\exists_x (up \otimes \sigma')$ is 
%$\otimes$-compact, and by Lemma\ref{undercomp} so is $\exists_x \sigma_1$, hence $\exists_x^{\sigma_1} B \in \mathcal{A}^+$.
%
%Since $\langle B, \sigma''\rangle$ is admissible, and $\sigma_1 \otimes \exists_x [(\sigma_0 \otimes \exists_x \sigma_1) \odiv \exists_x \sigma_1)]$
%
%Now, consider $up' = (\sigma_0 \otimes \exists_x \sigma_1) \odiv \sigma$. By hypothesis we have that 
%$\sigma = \sigma_0 \otimes \exists_x \sigma'$, thus 
%$up' = (\sigma_0 \otimes \exists_x \sigma_1) \odiv (\sigma_0 \otimes \exists_x \sigma') = 
%[(\sigma_0 \otimes \exists_x \sigma_1) \odiv \sigma_0] \odiv \exists_x \sigma') \leq \exists_x \sigma_1 \odiv \exists_x\sigma'$, 
%and since $\exists_x \sigma_1$ is $\otimes$-compact, so is $\exists_x \sigma_1 \odiv \exists_x \sigma'$ 
%by Lemma~\ref{preres} and thus $up'$ by Lemma\ref{undercomp}.
%\end{proof}

%We now establish two important results concerning computations.
%
%\begin{proposition}
%Let $\langle A, \sigma \rangle \rightarrow^* \langle B, \sigma' \rangle$
%be a computation. If $A \in \mathcal{A}$ and $\sigma \in {\mathcal C}^\otimes$, then
%$B \in \mathcal{A}^+$, $\sigma' \in {\mathcal C}^\otimes$ and $\sigma \leq \sigma'$.
 %\end{proposition}
%
%We now establish an additional result on the operational monotonicity.
% but first, we say that for a reduction $\xi: 
%The proposition is an immediate consequence of the lemmata above.
%
%\begin{lemma}[Operational mono]\label{opmonotonicity}
%Let $\langle A, \sigma \rangle \rightarrow_\Delta \langle B, \sigma' \rangle$
%be a reduction and $\rho \in  \C^\otimes$ such that $sv(\rho) \subseteq \Delta$. Then,
% there exists a reduction $\langle A, \sigma \otimes \rho \rangle \rightarrow_\Delta \langle B, \sigma' 
%\otimes \rho \rangle$.
%\end{lemma}
%
%The proof is straightforward, since as before $sv(\sigma \otimes \rho) \subseteq sv(\sigma) 
%\cup sv(\rho)$ and 
%moreover $\sigma, \rho \in  \C^\otimes$ ensure that $\sigma \otimes \rho \in  \C^\otimes$.
\begin{definition}[Increasing computations]\label{def:min}
Let $\gamma_0  \rightarrow_{\Delta_1} \gamma_1  \rightarrow_{\Delta_2} \gamma_2 \rightarrow_{\Delta_3} \dots$ be a
(possibly infinite) computation. 
%\marginpar{added ``infinite'' before computation}
It is increasing if $\Delta_k \subseteq \Delta_{k+1}$ for any $k >1$, and
it is minimally increasing if $\Delta_k + fn(\gamma_k) = \Delta_{k+1}$ for any $k>1$.
\end{definition}

What is noteworthy is that in such computation the sets $\Delta$'s are always uniquely identified,
once $\Delta_1$ is fixed.
Thanks to Lemma \ref{mono}, for the sake of simplicity and without loss of generality 
in the following we restrict our attention to minimally increasing computations, dropping
altogether the subscripts $\Delta$'s whenever they are irrelevant.

\section{Concluding Remarks}\label{sec:conclusion}
Polynomial constraints are used in many areas of system analysis and verification. For instance, when synthesising program invariants or analysing reachability of hybrid systems. A further application is represented by the generation of measures for proving termination of symbolic programs, as well as rewrite systems. This work strives in the direction of bringing polynomial constraints in the soft constraints framework. 

Our proposal moved from previous works, such as \cite{ipl17,jlamp17}, to build a new and more general
framework for representing soft constraints. In this paper, we have observed properties of residuation
in monoids equipped with partial orders or semi-lattices; moreover, we have introduced cylindric
and polyadic operators in terms of pomonoid actions. This allowed us to exploit
properties of $2_{fin}^V$ and $F(V)$ monoids and to generalise the notion of substitution,
by defining any possible function as a substitution and building a new axiomatisation,
which mirrors those obtained for previous definitions.
This provides a more elegant formalisation, as well as more general and compact laws.
Such results can be useful in giving an easier representation of soft constraints in SCSPs.

Furthermore, the absence of diagonals allowed the use of more general structures, which are not 
necessarily complete lattices, making our formalisation applicable to a larger class of case studies.
Also, using polyadic algebras with constraints can be used to model
many problems by using a comfortable polynomial representation. 

Polynomials can easily fit real-life problems and can be used in SCCP paradigm to describe a knowledge
basis shared among agents: indeed, a possible development of our works is a refitting of observational
and behavioural equivalences as described in \cite{jlamp17}, which needed complete lattices,
that could lead to the definition of a denotational semantics for SCCP.
As future work, we can also think of defining the class of Polynomial \emph{Soft} Constraint Satisfaction Problems (PSCSPs), 
as accomplished in \cite{pcsp09} with crisp constraints, in order to achieve a similar generalisation with respect to CSPs.

\bibliographystyle{splncs03}%splncs
\bibliography{main,softccp}




\end{document}
