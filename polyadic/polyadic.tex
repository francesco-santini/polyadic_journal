\documentclass{llncs}
\usepackage{mathptmx}

\usepackage{amsmath,amssymb,amsxtra,amsfonts,cancel}
\usepackage{graphicx,paralist}
\usepackage{url}
\usepackage{tikz-cd}
\usetikzlibrary{trees, arrows}
\usepackage{xspace}
%\usepackage{hyperref}
\usepackage{setspace}
\usepackage{tikz}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
\usepackage{textcomp}
\usepackage{soul}
\usepackage{listings}
\usepackage{mathtools}

\usepackage{todonotes}
% To disable notes without deleting them
%\usepackage[disable]{todonotes}

%\floatstyle{plain}
%\newfloat{myalgo}{tbhp}{mya}

\newenvironment{Algorithm}[2][tbh]%
{\begin{myalgo}[#1]
		\centering
		\begin{minipage}{#2}
			\begin{algorithm}[H]}%
			{\end{algorithm}
		\end{minipage}
	\end{myalgo}}
% to cut ------------------------------------------------------
%\usepackage{paralist}
%\usepackage[small]{caption}
%\usepackage{textcomp}
%\usepackage{times}
%\addtolength{\floatsep}{-5mm} \addtolength{\textfloatsep}{-5mm}
% -------------------------------------------------------------

\newtheorem{define}[theorem]{Definition}

\newtheorem{exa}[theorem]{Example}
\def\smallromani{\renewcommand{\theenumi}{\roman{enumi}}
        \renewcommand{\labelenumi}{(\theenumi)}}

%\def\bigodiv{{ \mathbf{\bigodot \hspace{-11pt} \boxempty \,\,}}}

\def\bigodiv{ {\text{ \large $\mathbf\odiv\hspace{-9.3pt} \div$}} }
\def\bigominus{ {\text{ \large $\mathbf\odiv\hspace{-9.3pt} -$}} }


%\defodiv{{ \odiv\hspace{-7.5pt} \div}}
\def\0{{\mathbf 0}}
\def\1{{\mathbf 1}}
\def\C{{\mathcal C}}
\newcommand{\rrarrow}{\longrightarrow}
\newcommand{\diag}[2]{d_{{#1}{#2}}}
\newcommand{\comment}[1]{}
\newcommand{\tell}{{\bf tell}}
\newcommand{\atell}{{\bf atell}}
\newcommand{\ask}{{\bf ask}}
\newcommand{\ostop}{{\bf stop}}
\newcommand{\retract}{{\bf retr}}
\newcommand{\rarrow}{\rightarrow}
\newcommand{\remove}{\rightarrow}
%introdotto per rimuovere le prove
\newcommand{\shortNoProof}[1]{ }

\def\ent{\vdash}
\def\monid{{\mathbf 0}}
\def\1{{\mathbf 1}}
\def\C{{\mathcal C}}
\def\K{{\mathcal K}}
\long\def\comment#1{}
\def\monop{\otimes}
\def\odiv{\, {\ominus\hspace{-7.7pt} \div} \,}
\def\monid{\mathbf{1}}

\newcommand{\SCCP}{\texttt{SCCP}\xspace}
\newcommand{\RefFig}[1]{Figure \nolinebreak\ref{#1}}
\newcommand\fnsep{\textsuperscript{,}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

\title{Soft Concurrent Constraint Programming with \\ Polyadic Structures}
%~\thanks{Research partially supported by the MIUR PRIN 2017FTXR7S ``IT-MaTTerS''.}


\author{Laura Bussi\inst{1}, Fabio Gadducci\inst{1}, 
Francesco Santini\inst{2}
} 
	\institute{Dipartimento di Informatica, University of Pisa, Italy \\
		\email{laura.bussi@phd.unipi.it} \qquad
		\email{fabio.gadducci@unipi.it}
		\and Dipartimento di Matematica e Informatica, University of Perugia, Italy\\
		\email{francesco.santini@unipg.it}
		}
	
\titlerunning{Polyadic Soft Constraints}
\authorrunning{Bussi, Gadducci, and Santini}

\maketitle

\begin{abstract}
???
\end{abstract}

\keywords{Concurrent constraint programming, polyadic algebras, residuated monoids.}

\section{Introduction}\label{sec:intro}
???

\section{An Introduction to Residuated Monoids}\label{sec:bg}

This section reports some results on residuated monoids,
which are the algebraic structure adopted for modelling
soft constraints in the following of the paper.
Results are mostly drawn from~\cite{jlamp17}, where also proofs can be found.


\subsection{Preliminaries on Ordered Monoids}\label{sec:lem}

The first step is to define an algebraic structure for modelling preferences,
where it is possible to compare values and combine them.
Our choice falls into the range of \emph{bipolar} approaches, in order to represent both positive and negative preferences: 
we refer to~\cite{ipl17} for a detailed introduction and a comparison with other proposals.
% such as~\cite{xxx}\todo{Manca citazione}.

\begin{definition}[partial order]
	A partial order (PO) is a pair $\langle A, \leq \rangle$ such that
	$A$ is a set and 
	$\leq \,\,\subseteq A \times A$ is a reflexive, transitive, and
	anti-symmetric relation.
	% and $\forall a \in A. \bot\leq a$.
	%
	%A partial order with bottom (POT) is a triple
	%$\langle A, \leq, \bot \rangle$ such that $\langle A, \leq \rangle$ is a PO and
	%$\forall a \in A. \bot \leq a$.
	%
	A (join) semi-lattice (SL) is a PO such that any non-empty finite  subset of $A$ has a
	least upper bound (LUB).
\end{definition}

%We write 
The LUB of a (possibly infinite or empty) subset $X \subseteq A$ is denoted $\bigvee X$, and it is clearly unique.
Should  they exist, $\bigvee A$ and $\bigvee \emptyset$ correspond respectively to the top, denoted as 
$\top$, and to the bottom, denoted as $\bot$, of the PO.

\comment{\begin{definition}[Compact elements]
An element $a \in A$ is compact 
%(or finite) 
if whenever $a \leq \bigvee Y$ for some $Y \subseteq A$
there exists a finite subset
$X \subseteq Y$ such that $a \leq \bigvee X$.
%
%Let $A^C \subseteq A$ be the set of compact elements of ${\mathbb C}$.
%Then ${\mathbb C}$ is algebraic if $\forall c \in A. c = \bigvee \{ d \in A^C \mid d \leq c\}$.
\end{definition}

We let $A^C \subseteq A$ denote the set of compact elements of ${\mathbb C}$. }

%We considered the LUBs of possibly infinite sets just for the sake of simplicity: 
%our proposal would fit also the finite case.
%
%Obviously, Ls also have the greatest lower bound for any subset $Y \subseteq A$.
%In the following we fix a BL ${\mathbb L} = \langle A, \leq, \monid \rangle$.

%\begin{definition}[compact elements]
%An element $a \in A$ is compact (or finite) if whenever $a \leq \bigvee Y$ there exists a finite subset
%$X \subseteq Y$ such that $a \leq \bigvee X$.
%%
%%Let $A^C \subseteq A$ be the set of compact elements of ${\mathbb C}$.
%%Then ${\mathbb C}$ is algebraic if $\forall c \in A. c = \bigvee \{ d \in A^C \mid d \leq c\}$.
%\end{definition}


%Note that for complete lattices the definition of compactness given above coincides with the one using
%directed subsets. It will be easier to generalize it, though, to compactness with respect to the monoidal operator (see Def.~\ref{def:compactness}).
%
%We let $A^C \subseteq A$ denote the set of compact elements of ${\mathbb C}$. Note however
%that $A^C$ might be trivial: indeed, in the the segment $[0, 1]$ of the reals
%with the usual order, only $0$ is a compact element. As we are going to see, the situation for the soft paradigm
%can be more nuanced.
%\marginpar{is algebraicity needed?}
%

\begin{definition}[monoid]
	A (commutative) monoid is a triple
	$\langle A, \monop, \monid \rangle$ such that $A$ is a set, $\monop: A \times A \rightarrow A$ is
	a commutative and associative function, and $\monid \in A$ is the \emph{identity} element,
	namely, $\forall a \in A. a \monop \monid = a$. % where $\monid \in A$ is the \emph{identity} element.
	
	A partially ordered (semi-lattice) monoid is a 4-tuple
	$\langle A, \leq, \monop, \monid \rangle$ such that 	
	$\langle A, \leq \rangle$ is a PO (SL) and $\langle A, \monop, \monid \rangle$ a monoid.
	
%	\noindent
%	A partially ordered monoid is monotone if 
%	satisfying
% 	A weakly ordered monoid is ordered if 
%	\begin{itemize}
%		\item $\forall a, b, c \in A. a \leq b \implies c \monop a \leq c \monop b$.
%	\end{itemize}
%	A semi-lattice monoid is an ordered (weakly so, respectively) monoid 
%	such that its underlying PO is an SL. 
\end{definition}

As usual, we use the infix notation: $a \monop b$ stands for $\monop(a,b)$.
\comment{The monoidal operator can be defined for any multi-set: it is given 
for a family of elements $a_i \in A$ indexed over a finite, non-empty
set $I$, and it is denoted by
$\bigotimes_{i \in I} a_i$.
%
If for an index set $I$ the $a_i$'s are different,
we write $\bigotimes S$ instead of $\bigotimes_{i \in I} a_i$
for the set $S = \{a_i \mid i \in I\}$.
%
Conventionally, we denote $\bigotimes \emptyset = \bot$.}

\begin{definition}[distributivity]
\label{dist}
Let $\langle A, \leq, \monop, \monid \rangle$ be a semi-lattice monoid.
It is distributive if
	for  any  non-empty finite  $X \subseteq A$
	\begin{itemize}
		\item $\forall a \in A.\,  a \monop  \bigvee X = \bigvee \{a \monop x \mid x \in X\}$.
	\end{itemize}

\end{definition}

Note that distributivity implies that $\otimes$ is monotone with respect to $\leq$.
\begin{remark}
% i.e., it holds
%	\begin{itemize}
%		%\item 
%		$\forall a, b, c \in A. a \leq b \implies c \monop a \leq c \monop b$.
%	\end{itemize}

	It is almost straightforward to show that our proposal encompasses many other formalisms in the literature.
	Indeed, distributive semi-lattice monoids are \emph{tropical} semirings (also known as dioids), 
	namely, semirings with an idempotent sum operator $a \oplus b$, which in our formalism is obtained as
	$\bigvee \{a, b\}$.
	% that is idempotent.
	%~\cite{tropical}. 
	If $\monid$ is the top of the SL we end up 
	in \emph{absorptive} semirings~\cite{golanShort}, 
	which are known as $c$-semirings 
	in the soft constraint jargon~\cite{jacm97} (see e.g.~\cite{ecai06} for a brief survey on residuation 
	for such semirings).
	Note that requiring the monotonicity of $\otimes$ and imposing $\monid$ to be the top of the partial order
	means that preferences are negative, i.e., 
	that it holds $\forall a, b \in A. a \monop b \leq a$.
\end{remark}

\begin{example}
Given a (possibly infinite) set $V$ of variables, two semi-lattice monoids are going to play a key role in the following sections. The first one is the semi-lattice monoid 
$\mathbb{M}(V) = \langle 2^V_{fin}, \subseteq, \cup, \emptyset \rangle$
of finite sub-sets of $V$, with the usual order given by sub-set inclusion.
For the second one, we start by defining the support of an endofunction $f\colon V \to V$ as the set $sv(f) = \{ x \in V \mid f(x)\neq x \}$ and
$F(V)$ as the set of functions $f\colon V \to V$ with finite support.
The semi-lattice monoid of interest is  $\mathbb{F}(V) = \langle F(V), id, \circ, \iota \rangle$ where 
$\iota$ is the identity function,  $\circ$ is function composition and $id$ is the discrete ordering on $F(V)$.
\end{example}

\bigskip
%
% COMMENTATO DA FILIPPO
%
%\begin{remark}
%The developments reported in Section~\ref{cypo} could be stated also for \emph{infinite} subsets 
%and for functions whose support is not necessarily finite. More on this later on.
%\end{remark}

%$a, b \in A$.
%
%The monoidal operator can be defined for any finite multiset: it is given for a family of elements
%$a_i \in A$ indexed over a finite set $I$, and it is denoted by
%$\bigotimes_{i \in I} a_i$.
%%
%Whenever for an index $I$ all the $a_i$'s are different,
%we simply write $\bigotimes S$ instead of $\bigotimes_{i \in I} a_i$
%for the set $S = \{a_i \mid i \in I\}$.
%%
%Conventionally, we will also usually denote $\bigotimes \emptyset = \top$.
%
%%smallskip
%%In the following we fix a IM ${\mathbb M} = \langle A, \monop, \monid \rangle$.
%
%We now move our attention to the domain of values we are going to consider.

\subsection{Remarks on Residuation}\label{sec:ror}
It is often needed to be able to ``remove'' part of a preference, due e.g. 
to the non-monotone nature of the language at hand
for manipulating constraints. 
%
The structure of our choice is given by residuated monoids~\cite{golanShort}. 
%
They introduce a new operator $\odiv$, which represents a ``weak'' (due to the presence of partial orders) inverse of $\otimes$.

\begin{definition}[residuation]\label{def:repo}
	A residuated monoid (RePO) is a 5-tuple $\langle A, \leq, \monop, \odiv, \monid \rangle$ such that
	$\langle A, \leq, \monop, \monid \rangle$ is a partially ordered monoid and
	$\odiv: A \times A \rightarrow A$ is a function satisfying $\forall a, b, c \in A. b \monop c \leq a \iff c \leq a \odiv b$.x
	An ReSL is an RePO such that the underlying PO is a SL.
\end{definition}

%In the following sections on oft CCP, we will often use absorptive RePOs, i.e., such that 
%	\begin{itemize}
%		\item[] $\forall a, \in A. a \leq 1$.
%	\end{itemize}
%
%However, 

%Residuation is monotone on the first argument: 
%$\forall a, b, c \in A. a \leq b \implies a \odiv c \leq b \odiv c$.
%Among other things, n
In order to confirm the intuition about weak inverses,
Lemma~\ref{lemma:residuation} below precisely states that residuation conveys the meaning of 
an approximated form of subtraction.
% which can be used to remove a constraint from another.
% operator.

\begin{lemma}\label{lemma:residuation}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an RePO.
	Then
	\begin{itemize}
		\item $\forall a, b \in A.\, a \odiv b = \bigvee \{ c \mid b \monop c \leq a\}$,
	\end{itemize}
\end{lemma}

\shortNoProof{
\begin{proof}
	By definition $a \odiv b$ is an upper bound of 
	$\{ c \mid b \monop c \leq a\}$ and $b \monop (a \odiv b) \leq a$.
	%
%	The latter property ensures the monotonicity of $\odiv$ on the first argument,
%	since by definition $a \odiv c \leq b \odiv c$ iff $c \monop (a \odiv c) \leq b$.
	%
%	As for the  monotonicity of $\monop$, it suffices to note that by definition
%	$a \leq (b \monop a) \odiv b$ and also by definition $c \monop a \leq c \monop b$ iff 
%	$a \leq (c \monop b) \odiv c$.
\qed
\end{proof}
}

%Note that by commutativity, 
%Thus $\monop$ is monotone (on both arguments), and
%the underlying monoid is ordered.
%while $\odiv$  is clearly anti-monotone on the second argument: 

In order to ease the verification of the algebraic structure, it is often needed
a characterisation of residuation via simpler properties,
as the ones given below.

\begin{lemma}
\label{mono}
Let $\langle A, \leq, \monop, \monid \rangle$ be a partially ordered monoid  and
	$\odiv: A \times A \rightarrow A$ a function. Then $\langle A, \leq, \monop, \odiv, \monid \rangle$ is an RePO if and only if
	\begin{itemize}
		\item $\forall a, b \in A. b \monop (a \odiv b) \leq a \leq (b \monop a) \odiv b$,
		\item $\forall a, b, c \in A.\, a \leq b \implies a \otimes c \leq b \otimes c$ and $a\odiv c \leq b \odiv c$.
\end{itemize}
\end{lemma}

\shortNoProof{
\begin{proof} ($\Longrightarrow$)
The first item is immediate. Now, let $a \leq b$. Since $b \leq (b \otimes c) \odiv c$ and 
$c \otimes (a \odiv c) \leq a$, the second item follows.

($\Longleftarrow$)
Using the monotonicity of $\odiv$ from $b \monop c \leq a$ we get
 $(b \monop c) \odiv b \leq a \odiv b$, and by the first item
 $c \leq a \odiv b$.
 %
 From the latter by the monotonicity of $\otimes$ we get
 $b \otimes c \leq b \otimes (a \odiv b)$, and by the first item
 $b \monop c \leq a$.
 %
%	Immediate: $a \odiv b$ is an upper bound of 
%	$\{ c \mid b \monop c \leq a\}$ and $b \monop (a \odiv b) \leq a$.
	%
%	The latter property ensures the monotonicity of $\odiv$ on the first argument,
%	since by definition $a \odiv c \leq b \odiv c$ iff $c \monop (a \odiv c) \leq b$.
	%
%	As for the  monotonicity of $\monop$, it suffices to note that by definition
%	$a \leq (b \monop a) \odiv b$ and also by definition $c \monop a \leq c \monop b$ iff 
%	$a \leq (c \monop b) \odiv c$.
\qed
\end{proof}
}

It is easy to show that in any RePO the $\odiv$ operator is also anti-monotone on the second argument, i.e., 
$\forall a, b, c \in A.\, a\leq b \implies  c\odiv b \leq c \odiv a$.
%
Other properties are also straightforward, such as 
$\forall a\in A. \monid \leq a \odiv a$, which in turn implies 
that $\forall a\in A. a \monop (a \odiv a) = a$ and
%
%, and \emph{iii)} $a \odiv (b \monop c) = (a \odiv b) \odiv c$.
%should $\monop$ be idempotent, $b \leq a$ implies $a \odiv b = a$.
%
$\forall a, b \in A. a < b \implies \monid \not \leq a \odiv b$, where
$a < b$ means $a \leq b$ and $a \neq b$.
%
%Residuation is monotone on the first argument:
%$\forall a, b, c \in A. a \leq b \implies a \odiv c \leq b \odiv c$.
%%falsa and if $b \leq a$, then $a \odiv b = \monid$. For more properties of residuation we refer to \cite[Table~4.1]{resbook}.
%
%
The latter fact suggests the definition below, which identifies sub-classes 
of residuated monoids that are suitable for an easier manipulation
of constraints (see e.g.~\cite{ecai06}).

\begin{definition}[localisation / invertibility]
	An RePO $\langle A, \leq, \monop, \odiv, \monid \rangle$ is
	\begin{itemize}
		\item
		\emph{localised} if $\forall a, b \in A. a \leq b \implies a \odiv b \leq \monid$;
		\item
		\emph{invertible} if $\forall a, b \in A. a \leq b \implies b \monop (a \odiv b) = a$.
	\end{itemize}
\end{definition}

Note that if a RePO is localised then $\forall a \in A. a \odiv a = \monid$.
%\marginpar{all RePO are localized?}

%\begin{remark}
%	Note that the equivalence $a \otimes ((a \otimes b) \odiv a) = a \otimes b$ always holds, even if the 
%	underlying RePO is not invertible. Indeed, we have by definition $a \otimes ((a \otimes b) \odiv a) 
%	\leq a \otimes b$, as $(a \otimes b) \odiv a \leq b$. We must check that $a \otimes ((a \otimes b) 
%	\odiv a) \leq a \otimes b \iff b \leq ((a \otimes b) \odiv a) \iff a \otimes b \leq a \otimes b$,
%	which is trivially true.
%\end{remark}

\begin{remark}\label{rmk:soft}
	Some well-known structures used for soft constraints are the 
	%\emph{Boolean} ($\langle \{\mathit{false},\mathit{true}\}, \mathit{false} \leq \mathit{true}, \wedge, \mathit{false}, \mathit{true}\rangle$), 
	\emph{Fuzzy} ($\langle [0,1], \leq,$ $\min, 1 \rangle$), \emph{Probabilistic} ($\langle [0,1], \leq,\allowbreak\times, 1 \rangle$), 
	and \emph{Tropical}   ($\langle \mathbb{R}^+, \geq, +, 0 \rangle$) semirings, for $\geq$ the inverse of the standard order 
	(thus $0$ the top of the SL). In all these cases the underlying monoids 
	are both invertible and localised, thus
	%
	the $\odiv$ operator can be also used to
	(partially) relax constraints (see again~\cite{ecai06}).
\end{remark}

Moving to ReSLs, next lemma ensures that residuation implies distributivity.

\begin{lemma}
	\label{dist2}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL.
	Then the underlying SL is distributive.
%	 and $X \subseteq A$ a finite set.
%	Then
%	\begin{itemize}
%		\item $\forall a \in A.\, a \monop  \bigvee X = \bigvee \{a \monop x \mid x \in X\}$.
%	\end{itemize}
\end{lemma}

\shortNoProof{
\begin{proof} Let $X \subseteq A$ be a finite non-empty set. 	
	%\paragraph{$\bigvee \{a \monop x \mid x \in X\} \leq a \monop  \bigvee X$}
	\[\forall x \in X.\, x \leq \bigvee X %\implies %\forall x \in X.\, x \leq (a \monop \bigvee X) \odiv a \implies\]
	\implies \forall x \in X.\, a \monop x \leq a \monop \bigvee X \implies \bigvee \{a \monop x \mid x \in X\} \leq a \monop  \bigvee X .\]

	%So, let us assume that $X$ is inhabited.
	%\paragraph{$a \monop  \bigvee X \leq \bigvee \{a \monop x \mid x \in X\}$}
	\[\forall y \in X.\, a \monop y \leq \bigvee \{a \monop x \mid x \in X\} \implies 
	\forall y \in X.\, y \leq (\bigvee \{a \monop x \mid x \in X\}) \odiv a \implies\] 
	\[ \implies \bigvee X \leq (\bigvee \{a \monop x \mid x \in X\}) \odiv a \implies 
	a \monop \bigvee X \leq \bigvee \{a \monop x \mid x \in X\} .\] 
\qed
\end{proof}
}
%Note that the proof does not require that $\otimes$ is monotone, which is thus a derived property.
%
Distributivity holds also for the empty set and for infinite sets, if the necessary LUBs exist.
%
Instead, it holds only partially for $\odiv$: this follows directly from the monotonicity of $\odiv$ on the first argument, 
since it implies that $x \odiv a \leq \bigvee X \odiv a$ for all $x \in X$.

\begin{lemma}
	\label{distodiv}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL and $X \subseteq A$ a finite non-empty set. Then 
	\begin{itemize}
		\item $\forall a \in A.\, \bigvee \{ x \odiv a \mid x \in X \} \leq \bigvee X \odiv a$
	\end{itemize}	
\end{lemma}

\shortNoProof{
\begin{proof}
Straightforward, since by the monotonicity of $\odiv$ in the first argument (Lemma~\ref{mono}) we get
% \[\forall x \in X.\,a \otimes (x \odiv a) \leq x \implies\]
 %\[\forall x \in X.\,a \otimes (x \odiv a) \leq \bigvee X \implies\]
 $\forall x \in X.\,x \odiv a \leq \bigvee X \odiv a$, which implies
 $\bigvee \{ x \odiv a \mid x \in X\} \leq \bigvee X \odiv a$.
% \[\]
\qed
\end{proof}
}

%\begin{remark}
Also this inequation holds for the empty set and for infinite sets, if the necessary LUBs exist.
%
Moreover, it also holds that $\bigvee \{ a \odiv x \mid x \in X \} \geq a \odiv \bigvee X$, since $\odiv$ is anti-monotone on the second argument.
%\end{remark}

\begin{proposition}\label{reabs}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL. The following are equivalent
	\begin{enumerate}
		\item $\forall a \in A.\, a \leq \1$
		\item $\forall a \in A.\, \1 \odiv a = \1$		
		\item $\forall a, b \in A.\, a \leq b \implies b \odiv a = \1$
	\end{enumerate}	
\end{proposition}

\shortNoProof
{
\begin{proof}
Note that $1$ immediately implies both $2$ and $3$, since by definition $a \leq b$ implies $\1 \leq b \odiv a$
and $\1$ is the top of the partial order.

For the second step, first note that both properties implies that $\1 \odiv a \leq \1$ for all $a \in A$. This is immediate
for $2$. As for $3$, %let us assume that $b \odiv a \leq \1$, and
consider $b = \bigvee \{\1, a \}$. By Lemma~\ref{distodiv} we have that
$\bigvee \{\1 \odiv a, a \odiv a\} \leq \bigvee \{\1, a \} \odiv a$. 
Hence, $\1 \odiv a \leq \1$ for all $a \in A$, and the result follows.

Finally, note that $\1 \odiv a \leq \1$ for all $a \in A$ implies that $\1 \odiv (\1 \odiv c) \leq \1$ for all $c \in A$, 
and since it always holds
that $c \leq \1 \odiv (\1 \odiv c)$, then $3$ implies $1$.
\qed
\end{proof}
}

%\begin{remark}
%In general, given an ReSL $\mathbb{M} = \langle A, \leq, \otimes, \odiv, \monid \rangle$, if $A \subseteq B$ such that $B(\otimes)$ is a group and $\odiv$
% is the inverse of $\otimes$, then $\mathbb{M}$ is fully $%\odiv$-distributive, which follows from $\mathbb{M}$ is distributive for $\otimes$. \\
%Consider, for istance, $\mathbb{M} = \langle \{0,...,5\},\geq,\oplus,\ominus,0 \rangle$, where $\oplus$ and $\ominus$ are the bounded sum and subtraction (e.g. $2 \oplus 4 = 5$, $2 \ominus 4 = 0$): 
%it is clear that, in this case, distributivity holds for $\ominus$, as long as $a \geq b \implies b \ominus a = 0$. \\
%\todo{un esempio dove $\odiv$ non distribuisce}
%In the following example it is shown that distributivity for $\odiv$ could hold partially, since we choose a residuation operator which is not the inverse of $\otimes$.
%\end{remark}

%\begin{remark}\label{rmk:softUnit}
%The proposition above provides an important characterisation for all absorptive ReSLs, including all those mentioned in Remark~\ref{rmk:soft}.
%\end{remark}

There are some important classes of ReSLs  such that $\odiv$ is easily proved to be distributive in the first argument,
while it is not so with respect to the second argument, not even in the absorptive case.

\begin{lemma}
	\label{distodiv2}
	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL such that $\langle A, \leq \rangle$ is a total order and $X \subseteq A$ a finite non-empty set. Then 
	\begin{itemize}
		\item $\forall a \in A.\, \bigvee \{ x \odiv a \mid x \in X \} = \bigvee X \odiv a$
	\end{itemize}	
\end{lemma}

\shortNoProof{
\begin{proof}
If $\langle A, \leq \rangle$ is a total order and $X$ is finite and non-empty we have that $\bigvee X \in X$, and since $\odiv$ 
is monotone on the first argument (see Lemma~\ref{mono}) the result follows.
\qed
\end{proof}
}

\begin{example}
\label{nodist2}
%Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL such that $\langle A, \leq \rangle$ is a total order.
%Then, it holds that $\bigvee \{ x \odiv a \mid x \in X \} = \bigvee X \odiv a$ for all elements $a$ and (finite, non-empty) subsets $X$.
%In fact, if $\langle A, \leq \rangle$ is a total order and $X$ is finite and non-empty we have that $\bigvee X \in X$, and since $\odiv$ 
%is monotone on the first argument (see Lemma~\ref{mono}), the result follows.
%
Let $n$ be a positive integer and $[n] = \{0, \ldots, n\}$ the segment of integers from $0$ to $n$. We can now define the (bounded) monoid $\mathbb{M}_n$ 
as the tuple $\langle [n], \geq, \oplus, \ominus, 0 \rangle$, where $\oplus$ and $\ominus$ are the bounded sum and subtraction, 
which are given as $m\oplus p = min\{n, m+p\}$ and $m\ominus p = max\{0,m-p\}$.

Now, it can be shown that $\mathbb{M}_n$ is an absorptive ReSL, and since it is a total order,
$\ominus$ is  distributive on the first argument.
%
However, in general it is not distributive on the second one. Consider an integer $m$ such that 
$m \neq n$ and the set $\{m, m+1\}$:
we then have that $(m+1) \ominus \bigvee\{m, m+1\} = 1$,
while instead $\bigvee\{(m+1) \ominus m, (m+1) \ominus (m+1)\} = 0$.
\end{example}

\comment{
\begin{example}
Given $A = \{0,a,b,c,d,e\}$, consider the following partial order:
	\begin{center}
		\begin{tikzpicture}
			\node (top) at (0,0)  {$0$};
			\node (a) [below of= top] {$a$};
			\node [below left of=a] (left) {$b$};
			\node [below right of=a] (right) {$c$};
			\node (d) [below right of=left] {$d$};
			\node (e) [below of=d] {$e$};
			\draw [thick] (top) -- (a);
			\draw [thick] (a) -- (left);
			\draw [thick] (a) -- (right);
			\draw [thick] (left) -- (d);
			\draw [thick] (right) -- (d);
			\draw [thick] (d) -- (e);
		\end{tikzpicture}
	\end{center}
and $\mathbb{M} = \langle A, \geq, \otimes, \odiv, 0 \rangle$, where $\otimes$ and $\odiv$ are defined as follows:
\begin{center}
	\begin{tabular}{@{} *{7}{c} @{}}
	\\ $\otimes$ \ & 0 \ & a \ & b \ & c \ & d \ & e
	\\ 0 \ & 0 \ & a \ & b \ & c \ & d \ & e
	\\ a \ & a \ & b \ & c \ & d \ & e \ & f
	\\ b \ & b \ & c \ & d \ & d \ & e \ & e
	\\ c \ & c \ & d \ & d \ & d \ & e \ & e
	\\ d \ & d \ & e \ & e \ & e \ & e \ & e
	\\ e \ & e \ & e \ & e \ & e \ & e \ & e
	\end{tabular}
\\	
	\begin{tabular}{@{} *{7}{c} @{}}
	\\ $\odiv$ \ & 0 \ & a \ & b \ & c \ & d \ & e
	\\ 0 \ & 0 \ & 0 \ & 0 \ & 0 \ & 0 \ & 0
	\\ a \ & a \ & 0 \ & 0 \ & 0 \ & 0 \ & 0
	\\ b \ & b \ & a \ & 0 \ & 0 \ & 0 \ & 0
	\\ c \ & c \ & a \ & 0 \ & 0 \ & 0 \ & 0
	\\ d \ & d \ & c \ & c \ & b \ & 0 \ & 0
	\\ e \ & e \ & d \ & b \ & c \ & a \ & 0
	\end{tabular}
\end{center}
Then $\mathbb{M}$ is an absorptive ReSL with $0$ the top of the partial order, since it behaves as the ReSL in the example above, except for $b$ and $c$: thus, in this case, $\bigvee \{b,c\} = a$. \\
It's now easy to show that $\odiv$ is not distributive for the first argument: $\bigvee{b \odiv a, c \odiv a} = a$ and $\bigvee\{b,c\} \odiv a = a \odiv a = 0$.
\end{example}

%
%We can proove $\bigvee X \odiv a = \bigvee \{ x \odiv a \mid x \in X \}$ under the following hypotesis.
%
%\begin{lemma}
%	\label{distodiv2}
%	Let $\langle A, \leq, \monop, \odiv, \monid \rangle$ be an ReSL.
%	If $a \otimes (x \odiv a) = x = (a \otimes x) \odiv a$, then $\bigvee X \odiv a = \bigvee \{ x \odiv a \mid x \in X \}$.
%\end{lemma}
%
%\begin{proof}
% \[\bigvee X = \bigvee \{ a \otimes (x \odiv a) \mid x \in X \} \implies\]
% \[\bigvee X = a \otimes \bigvee \{ x \odiv a \mid x \in X \} \implies\]
% \[\bigvee X \odiv a = (a \otimes \bigvee \{ x \odiv a \mid x \in X\}) \odiv a \implies\]
% \[\bigvee X \odiv a = \bigvee \{ x \odiv a \mid x \in X\}.\]
% \[\]
%\end{proof}
%
%[Qui avevi fatto una correzione, mettendo nell'ipotesi una disuguaglianza al posto della seconda uguaglianza, ma in quel modo non potrei provare l'ultimo passaggio, quindi te la rispedisco cos\`{i}. 
%Magari ne discutiamo quando ci vediamo.]
%\\

%Distributivity over $\bigvee$ implies that $\monop$ is
%monotone in both arguments.
%%as well as $\forall a \in A. a \monop \bot = \bot$.

%%
%In the following, we fix a BLIM ${\mathbb S} = \langle A, \leq, \monop \rangle$.
%%
%The next step is to provide a suitable notion of infinite composition. The definition below is taken from~\cite{CLIM}
%(but see also~\cite[p.~42]{golan}).
%
%\begin{definition}[infinite composition]
%Let $I$ be a (possibly countable) set of indexes. Then, the composition $\bigotimes_{i \in I} a_i$
%is defined as $\bigvee_{J \subseteq I} \bigotimes_{j \in J} a_j$ for all finite subsets $J$.
%\end{definition}

%%\marginpar{distributivity wrt. $\vee$ or wrt. $\wedge$ coincide?}
%Thanks to distributivity, we can show that
%$\bigotimes$ is monotone, i.e., $\forall j \in I. a_j \leq b_j \implies
%\bigotimes_{i \in I} a_i \leq \bigotimes_{i \in I} b_i$.

%We now extends the notion of compactness.
%
%\begin{definition}[$\monop$-compact elements]\label{def:compactness}
%An element $a \in A$ is $\monop$-compact (or $\monop$-finite) if whenever $a \leq \bigotimes_{i \in I} a_i$
%then there exists a finite subset $J \subseteq I$ such that $a \leq \bigotimes_{j \in J} a_j$.
%
%Let $A^\monop \subseteq A$ be the set of $\monop$-compact elements of ${\mathbb S}$. Then ${\mathbb S}$ is
%$\monop$-algebraic if $\forall c \in A. c = \bigotimes \{ d \in A^\monop \mid d \leq c\}$.
%\marginpar{now $\monop$-algebraicity is incorrect}
%\end{definition}

%We let $A^\monop \subseteq A$ denote the set of $\monop$-compact elements of ${\mathbb S}$.
%%
%It is easy to show that a compact element is also $\monop$-compact.
%%
%Indeed, the latter notion is definitively more flexible.
%%
%Let us consider again the segment $[0, 1]$ of the reals, yet now with the inverse of the usual order (as used
%in the probabilistic SCPs). Instead of the LUB, an alternative monoidal
%product can be just the multiplication.
%%
%Since any infinite multiplication tends to $0$, then all the elements are
%$\monop$-compact, except the top element itself, that is, precisely $0$.
%\marginpar{is $\monop$-algebraicity needed?}
}

\comment{
\subsection{On residuation and semirings}

We now consider \emph{semirings} equipped with a partial order~\cite[Chapter~2]{golanShort}.

\begin{definition}[semirings]
	A (commutative) semiring is a 5-tuple
	$\langle A, \monop, \monop, \monid, \1 \rangle$ such that $\langle A, \monop, \monid \rangle$
	and $\langle A, \monop, \1 \rangle$ are (commutative) monoids
	satisfying
	\begin{itemize}
		\item $\forall a \in A. a \monop \monid = \monid$
		\item $\forall a, b, c \in A. a \monop (b \monop c) = (a\monop b) \monop (a \monop c)$
	\end{itemize}
	An ordered semiring is a 6-tuple
	$\langle A, \leq, \monop, \monop, \monid, \1 \rangle$
        such that  $\langle A, \leq, \monop, \monid \rangle$ is an ordered monoid and 
   	$\langle A, \monop, \monop, \monid, \1 \rangle$ a semiring satisfying
	\begin{itemize}
			\item $\forall a, b, c \in A. a \leq b \wedge \monid\leq c \implies c \monop a \leq c \monop b$
	\end{itemize}
\end{definition}

We often use an infix notation, as $a \monop b$ for $\monop(a,b)$.


[A QUESTO PUNTO BISOGNA VEDERE QUALI DI QUESTE TRE PROPRIETA'
DELL'ordered SEMIRING POSSONO DISCENDERE DA QUELLE DELLA RESIDUAZIONE,
IN MODO DA AVERE GLI EQUIVALENTI DEI LEMMA 3 E 4]

[ MA 1 MI SERVE A QUALCOSA?]

\begin{definition}[residuation, II]
	A residuated semiring (ReS) is a 7-tuple $\langle A, \leq, \monop, \odiv, \monop, \monid, \1 \rangle$
	such that	$\langle A, \leq, \monop, \odiv, \monid \rangle$
	 is a residuated monoid and $\langle A, \leq, \monop, \monop, \monid, \1 \rangle$ an ordered semiring,
	  satisfying 
	\begin{itemize}
            ????
	\end{itemize}
	A residuated SSL (ReSSL) is an ReS such that the underlying PO is a SL.
\end{definition}

[COSA PUO' SERVIRE COME ASSIOMA?]

%In the following sections on oft CCP, we will often use absorptive RePOs, i.e., such that 
%	\begin{itemize}
%		\item[] $\forall a, \in A. a \leq 1$.
%	\end{itemize}
%
%However, 
}

\comment{
Indeed, there are many classes of absorptive and idempotent ReSLs such that $\odiv$ 
is not distributive in either arguments.

\begin{example}
\label{notdistr}
First of all, note that a complete sup-lattice $\langle A, \leq \langle$ (i.e., admitting a sup for all subsets 
of $A$) can be turned into a ReSL. Indeed, $\otimes$ is just the meet, so we have that 

\begin{itemize}
\item $a \otimes b = \bigvee \{c \mid c \leq a \wedge c \leq b\}$
\item $a \odiv b = \bigvee \{c \mid c \otimes b \leq a\}$
\end{itemize}


$$x \otimes y = \bigg \{\begin{array}{ll}
	\1 & \mbox{ if } y \leq x \\
	x & \mbox{ if } y = \1 \\
	\bot & \ otherwise
	\end{array}$$

both meetand divis




the bounded sum $\oplus$ is here idempotent, $0$ is still 
the identity. We can make it int
of three otherwise unrelated elements, 
so that for all elements $x$ we have $x \otimes x = \1 \otimes x = x$ \
and furthermore $a \otimes b = a \otimes c = b \otimes c  = \1$.

We now add the bottom element $\bot$, in order to obtain a complete lattice.
Then $\otimes$ is extended in the expected way, so that $\bot$ is absorbing.
%
The resulting semi-lattice monoid is absorptive and residuated, with $\odiv$ defined as

$$x \odiv y = \bigg \{\begin{array}{ll}
	\1 & \mbox{ if } y \leq x \\
	x & \mbox{ if } y = \1 \\
	\bot & \ otherwise
	\end{array}$$
%
Thus, $\odiv$ does not distribute, since 
$\bigvee \{a \odiv c, b \odiv c\}  = \bot < \1 = \1 \odiv c = \bigvee \{a, b\} \odiv c$.
\end{example}
}

\comment{
\begin{example}
\label{notdistr}
Let us consider the monoid $S = \langle \{p,u,n,t\}, \otimes_s, u \rangle$ (with $t$ the top 
of three otherwise unrelated elements): 
$p$ and $n$ intuitively represent the sign of an integer, $t$ tells us that 
the sign cannot be determined, $u$ is the zero
and $\otimes_s$ (which is idempotent) tells us the sign of the addition of two integers, so that 
for all elements $x$ we have
\[x \otimes_s x = u \otimes_s x = x \mbox{  and  } t \otimes_s x = p \otimes_s n = t\]
%
We now add the bottom, in order to obtain a complete lattice.
The $\otimes_s$ is extended in the expected way,  so that $\bot$ is absorbing.
%
Intuitively, $\bot$ states that an element is unsigned:
a pattern the reader familiar with abstract interpretation formalisms will recognise.

The resulting semi-lattice monoid is residuated, with $\odiv$ defined as

$$x \odiv y = \bigg \{\begin{array}{ll}
	t & y \leq x \\
	\bot & \ otherwise
	\end{array}$$
%
Thus, $\odiv$ does not distribute, since 
$\bigvee \{p \odiv n, u \odiv n\}  = \bot < \bigvee \{p, u\} \odiv n = t \odiv n = t$.
\end{example}
}

\section{An Alternative Proposal for Costraint Manipulation}
\label{newpro}

This section presents our personal take on polyadic algebras for ordered monoids:
the standard axiomatisation of e.g.~\cite{sagi2013} has been completely 
reworked, in order to be adapted to the constraints formalism.
%
We close the section by offering some preliminary insights on 
the laws for polyadic operators in residuated monoids.

\subsection{Cylindric and Polyadic Operators for Ordered Monoids}
\label{cypo}
We now introduce two families of operators 
%(cylindric and polyadic ones) 
that will be used
for modelling variables hiding and substitution, which represent
key features in languages for manipulating constraints.
%
One is a well-known abstraction for existential quantifiers,
the other an axiomatisation of the notion of
substitution, and it is proposed as a weaker  alternative 
to diagonals~\cite{popl91}, the standard tool for modelling 
equivalence in constraint programming.\footnote{``Weaker 
alternative'' here means that diagonals allow for axiomatising
substitutions at the expenses of working with complete
partial orders: see e.g.~\cite[Definition 11]{jlamp17}.}
%

\comment{\smallskip
Our first step is the introduction of a technical notion that allows for 
factorising the common properties in the definition of the two families of operators.

\begin{definition}[pomonoid action]
\label{pomo}
Let $\mathbb{M} = \langle A, \leq, \monop, \monid \rangle$ be a partially ordered monoid and $\mathbb{P} = \langle S, \leq \rangle$ a partial order.
A pomonoid action of $\mathbb{M}$ on $\mathbb{P}$ is a function $\phi: A \times S \rightarrow S$ such that
	\begin{itemize}
	     \item $\forall s \in S.\ \phi(\monid, s) = s$,
         \item $\forall a, b \in A,\ s \in S.\ \phi(a, \phi(b, s)) = \phi(a \otimes b, s)$,
         \item $\forall a, b \in A,\ s, t \in S.\ a \leq b\, \wedge\, s \leq t \implies \phi(a, s) 
         \leq \phi (b, t)$.
            % \item $\forall a, b \in A,\ s \in S.\ a \leq b \implies \phi(a, s) \leq \phi (b, s)$.
	\end{itemize}
\end{definition}

The first two requirements just state
that $\phi$ is a monoid action of $\mathbb{M}$ on $S$, while the latter states that $\phi$ is monotone. Sometimes, we say that $\mathbb{P}$ is an $\mathbb{M}$-PO.}

\subsubsection{Cylindric operators.}
We fix a partially ordered monoid $\mathbb{S} = \langle A, \leq, \monop, \monid \rangle$
and a set $V$ of variables, and we then define a family of cylindric operators axiomatising existential quantifiers.

\begin{definition}[cylindrification]\label{cyli}
	A cylindric operator $\exists$ over $\mathbb{S}$ and $V$ ia family of monotone operators
	$\exists_x : A \rightarrow A$ indexed by elements in V such that for all 
	$a, b \in A$ and $x, y \in V$
	%\todo{$2_f^V$ non e' stato definito prima e/o f non si sa cosa e' qui}
	\begin{enumerate}
	     \item $a \leq \exists_x a$,
         \item $\exists_x \exists_y a = \exists_y \exists_x a$,
         %\item $\forall a, b \in A.\ X \subseteq Y\wedge a \leq b \implies  \exists(X, a) = \exists(Y, b)$,
	     %\item $\exists(X, \monid) = \monid$,
	     \item $\exists_x (a \monop \exists_x b) = \exists_x a \monop \exists_x b$.
	\end{enumerate}
	
	\noindent Let $a \in A$. The \emph{support} of $a$ is the set of variables 
	$sv(a) = \{ x \mid \exists_x a \neq a\}$. 
	% and the set of unsupported variables of $a$ is the set of variables $uv(a) =  V \setminus sv(a)$.
\end{definition}

%Note that, since by Definition~\ref{pomo} we have $\exists(\emptyset, a) = a$, the requirements of Definition~\ref{cyli} trivially hold 
%whenever $X$ is the empty set.
%
%The first two conditions tell us that $\exists$ is a monoid action of $M(V)$ over $A$. Condition $3$ states
%that $\exists$ is a monotone function. Finally, the last two conditions state how $\exists$ interacts with the 
%monoidal structure on $\mathbb{S}$.
%
%\begin{remark}
%TODO bisogna vedere cosa altro serve, e se qualche propriet\`a \`e derivata.
%Cosa succede se $\mathbb{S}$ \`e un SL? Questo impatta sui LUB in M(V)?
%\end{remark}
%
%
%Note also that $\exists(X, \monid) = \monid$ would be a consequence of monotonicity,
%should $\monid$ be the top element. Also, the support is not necessarily finite.
%Finally, and importantly, note that 
%$X \cap sv(\exists(X, a)) = \emptyset$.

%\smallskip
%In the following, we often use $\exists_X a$ for $\exists(X, a)$, and $\exists_x a$ whenever $X = \{x\}$.

\subsubsection{Polyadic operators.}
We now move to define a family of operators axiomatising substitutions.  
They interact with quantifiers, thus, beside a partially ordered monoid $\mathbb{S}$
and a set $V$ of variables, we fix a cylindric operator $\exists$ over ${\mathbb S}$ and $V$.

As for notation, for a function $\sigma: V \rightarrow V$ and a set $X \subseteq V$, we denote by 
$\sigma \mid_{X}: X \rightarrow V$ the obvious restriction, and
by $\sigma^{c}(X) \subseteq V$ the counter-image of $X$ along $\sigma$.
%~\footnote{We are not going to need the other standard component proposed in the literature , i.e., \emph{diagonals}: a %family of elements $d_{x, y} \in A$ indexed by pairs of elements in $V$.}


\begin{definition}[polyadification]
	\label{def:poly}
	A polyadic operator $s$ for $\exists$ is a a family of monotone operators $s_\sigma: A \rightarrow A$
	indexed by elements in $F(V)$ such that for all $x \in V$ and $\sigma, \tau\in F(V)$
	\begin{enumerate}
		\item $sv(\sigma) \cap sv(a) = \emptyset \implies s_\sigma a = a$
		\item $\forall a, b \in A.\ s_\sigma(a \monop b) = s_\sigma a \monop s_\sigma b$,
        \item $\forall a \in A.\ \sigma \mid_{sv(a)} = \tau \mid_{sv(a)} \implies s_\sigma a 
        = s_\tau a$,
        \item $\forall a \in A.\ \exists_x s_\sigma a = \begin{cases}
			s_\sigma \exists_y a &\text{if $\sigma^c(x) = \{y\}$}\\
			s_\sigma a &\text{if $\sigma^c(x) = \emptyset$}
			\end{cases}$.				
    \end{enumerate}
\end{definition}

%Clearly item $3$ always holds for an empty $X$.
%
A polyadic operator offers enough structure for modelling variable substitution. 
%
In the following, we fix a polyadic operator $s$ for $\exists$.

\comment{\begin{remark}
The laws are directly adapted from~\cite{sagi2013}, with the exception of $2$, which 
is stated as for a finite non-empty $X \subseteq V$ and $a \in A$
	\begin{itemize}
          \item[\emph{2'}.] $\sigma \mid_{V \setminus X} = \tau \mid_{V \setminus X}
		         \implies \forall a\in A.\ s(\sigma, \exists (X, a)) = s(\tau, \exists (X, a))$.
        \end{itemize}
However, the two formulations are equivalent. Indeed, note that
$\sigma \mid_{V \setminus X} = \tau \mid_{V \setminus X}$ implies 
$\sigma \mid_{sv(a) \setminus X} = \tau \mid_{sv(a) \setminus X}$, 
which in turn implies that 
$\sigma \mid_{\exists (X, a)} = \tau \mid_{\exists (X, a)}$, and 
assuming item $2$ the result follows.
%
For the vice-versa, first of all note that 
$\sigma \mid_{V \setminus X} = \tau \mid_{V \setminus X}$
coincides with $\sigma \mid_{Y \setminus X} = \tau \mid_{Y \setminus X}$
for $Y = sv(\sigma) \cup sv(\tau) \subseteq V$, and that $Y$ is finite
since both $\sigma$ and $\tau$ are finitely supported.
Now, $\sigma \mid_{sv(a)} = \tau \mid_{sv(a)}$ implies that 
$\sigma \mid_{Y \setminus (Y \setminus sv(a))} = \tau \mid_{Y \setminus (Y \setminus sv(a))}$,
thus by $2a$ we have 
$s(\sigma, \exists (Y \setminus sv(a), a)) = s(\tau, \exists (Y \setminus sv(a), a))$.
Since by definition we have $\exists (Y \setminus sv(a), a)) = a$, the result follows.
\end{remark}
}

%\begin{remark}
%Note also that $\sigma(\sigma^{c}(X)) \subseteq X$, so, when restricted to singleton, we have that item %$3$ in Definition~\ref{def:poly} is equivalent to
%\begin{itemize}
%          \item[\emph{3'}.] $\forall a\in A.\ \sigma^{c}(x) = \{y\} \implies \exists_x s_{\sigma} a =  %s_\sigma \exists_y a$,
%          \item[\emph{3''}.] $\forall a\in A.\ \sigma^{c}(x) = \emptyset \implies \exists_x s_{\sigma} %a =  s_\sigma a$.
%\end{itemize}
%\end{remark}

%\noindent As we did for $\exists$, we define the support of $\sigma$ as follows:
%\begin{itemize}
%\item $sv(\sigma) = \bigcap X \subseteq V \mid \sigma(X) \neq X$
%\end{itemize}

\subsection{Cylindric and Polyadic Operators for Residuated Monoids}
\label{cyre}
Both algebraic structures introduced in the previous section are quite standard,
even if polyadic operators are less-known in the soft-constraints literature:
we tailored their presentation to our needs, and indeed the properties
presented in Section~\ref{propo} appear to be original. It is now time to consider 
the interaction of such structures with residuation. 
%
To this end, in the following we assume that 
$\mathbb{S}$ is a RePO (see Definition~\ref{def:repo}).


\begin{lemma}
Let $X \subseteq V$ be finite. Then it holds
	\begin{itemize}
         \item $\forall a, b \in A.\ \exists_x(a \odiv \exists_x b) \leq \exists_x a \odiv \exists_x b$.
	\end{itemize}
\end{lemma}

\begin{proof}
 \[\exists_x b \otimes (a \odiv \exists_x b) \leq a \implies
   \exists_x(\exists_x b \otimes (a \odiv \exists_x b)) \leq \exists_x a \implies\]
 \[\exists_x b \otimes \exists_x(a \odiv \exists_x b)) \leq \exists_x a \implies
   \exists_x(a \odiv \exists_x b) \leq \exists_x a \odiv \exists_x b\]
   \qed
\end{proof}

\begin{remark}
Looking at the proof above, it is clear that $\exists_x(a \odiv \exists_x b) \leq \exists_x a \odiv \exists_x b$
is actually equivalent to state that
$\exists_x(a \monop \exists_x b) \geq \exists_x a \monop \exists_x b$.
\end{remark}

%\begin{remark}
%\todo{un esempio dove $\odiv$ non distribuisce}
%\end{remark}

Similarly, it is easy to show that it holds $\forall a, b \in A.\ \exists_x(\exists_x a \odiv b) \leq \exists_x a \odiv \exists_x b$. 
%
A similar result relates residuation and polyadic operators.
%the following lemma holds.
%\todo{Mettere motivazione Lemma?}

\begin{lemma}
Let $\sigma \in F(V)$. Then it holds
\begin{itemize}
\item $\forall a,b \in A.\ s_\sigma (a \odiv b) \leq s_\sigma a \odiv s_\sigma b$.
\end{itemize}
Furhtermore, if $\sigma$ is invertible, then it holds
\begin{itemize}
\item $\forall a,b \in A.\ s_\sigma (a \odiv b) = s_\sigma a \odiv s_\sigma b$.
\end{itemize}
\end{lemma}

\begin{proof}
\[ a \otimes (b \odiv a) \leq b \implies \]
\[ s_\sigma [a \otimes (b \odiv a)] \leq s_\sigma b \implies \]
\[ s_\sigma a \otimes s_\sigma(b \odiv a) \leq s_\sigma b \implies \]
\[ s_\sigma (b \odiv a) \leq s_\sigma b \odiv s_\sigma a \]

As for the second item, note that $\sigma$ invertible implies $s_{\sigma^{-1}} s_{\sigma} a = a 
= s_{\sigma} s_{\sigma^{-1}} a$. Then we have:

\[ s_\sigma b \otimes (s_\sigma a \odiv s_\sigma b) \leq s_\sigma a  \implies \]
\[ s_{\sigma^{-1}} (s_\sigma b \otimes (s_\sigma a \odiv s_\sigma b))
\leq s_{\sigma^{-1}} s_\sigma a  \implies \]
\[ s_{\sigma^{-1}} s_\sigma b \otimes s_{\sigma^{-1}} (s_\sigma a \odiv s_\sigma b) \leq a \implies \]
\[ b \otimes s_{\sigma^{-1}} (s_\sigma a \odiv s_\sigma b) \leq a \implies \]
\[ s_{\sigma^{-1}} (s_\sigma a \odiv s_\sigma b) \leq a \odiv b \implies \]
\[ s_\sigma (s_{\sigma^{-1}} (s_\sigma a \odiv s_\sigma b)) \leq s_\sigma (a \odiv b) \implies \]
\[ s_\sigma a \odiv s_\sigma b \leq s_\sigma (a \odiv b) \]
\end{proof}

\subsection{Polyadic Soft Constraints}\label{sec:softconstraints}
\label{subsec:inst} 
We are now ready to advance our proposal of soft constraints;  follows yet generalises \cite{scc},
whose underlying algebraic structure is the one of absorptive semirings.

\begin{definition}[(soft) constraints]\label{def:softconstraints}
	Let $V$ be a set of variables, $D$ a finite domain of interpretation
	and ${\mathbb S} = \langle A, \leq, \monop, \odiv, \monid \rangle$ a ReSL.
	A \emph{(soft) constraint} $c: (V \rightarrow D) \rightarrow
	A$ is a function associating a value in $A$ with each assignment
	$\eta: V\rightarrow D$ of the variables.
\end{definition}

In this section and in the following one, we denote by $\mathcal{C}$ the set of constraints that can be
built starting from chosen $\mathbb S$, $V$, and $D$. The application of a
constraint function $c:(V \rightarrow D) \rightarrow A$ to a variable
assignment $\eta:V\rightarrow D$ is denoted $c\eta$.  

Even if
a constraint involves all the variables in $V$, it may depend on
the assignment of a finite subset of them, called its support. For
instance, a binary constraint $c$ with $supp(c)=\{x,y\}$ is a function
$c: (V\rightarrow D)\rightarrow A$ that depends only on the
assignment of variables $\{x,y\}\subseteq V$, meaning that two
assignments $\eta_1, \eta_2: V \rightarrow D$ differing only for the
image of variables $z \not \in \{x,y\}$ coincide (i.e., $c\eta_1 =
c\eta_2$).
%
The support corresponds to the classical notion of scope of a
constraint.  We often refer to a constraint with support $X$ as $c_X$.
Moreover, an assignment over a support $X$ of cardinality $k$ is concisely
represented by a tuple $t$ in $D^k$, and we often write $c_X(t)$
instead of $c_X\eta$.

\smallskip
The set of constraints forms a ReSL, with the structure
lifted from ${\mathbb S}$.

\begin{lemma}[the ReSL of constraints]\label{prop:soft}
	The ReSL of constraints $\mathbb C$ is
	defined as the tuple $\langle {\mathcal C}, \leq, \monop, \odiv, \monid \rangle$ such that
	
	\begin{itemize}
		\item $c_1 \leq c_2$ if $c_1\eta\leq c_2\eta$ for all $\eta: V \rightarrow D$,
		\item $(c_1\monop c_2)\eta = c_1\eta\monop c_2\eta$, %for $c_1, c_2\ \in {\mathcal C}$
		\item $(c_1\odiv c_2)\eta = c_1\eta\odiv c_2\eta$, %for $c_1, c_2\ \in {\mathcal C}$
		\item $\monid \eta = \monid$.
	\end{itemize}
\end{lemma}


Combining constraints by the $\monop$ operator
means building a new constraint whose support involves at most
the variables of the original ones. The resulting constraint  associates with
each tuple of domain values for such variables the element
that is obtained by multiplying  those associated by the
original constraints to the appropriate sub-tuples.
%
%Residuation works as expected (i.e., $(c_1\odiv c_2)\eta = c_1\eta\odiv c_2\eta$),
%and 
%Also, the bottom is the constant function mapping all $\eta$ to $\bot$.

%\begin{example}[A simple CLIM]\label{execlim}
%Let us consider a CLIM $\mathbb S$, 
%and as $D$ a finite subset of the elements of the CLIM.
%A polynomial with variables in $V$ 
%and elements of the CLIM as coefficients
%such as $ux \, \hat{+} \, vy \, \hat{+} \, z$
%can be interpreted as the soft constraint associating 
%with a function $\eta: V \rightarrow D$ the value 
%$\bigvee \{u \monop \eta(x), v \monop \eta(y), z \}$.
%The composition of such constraints is straightforward, while 
%the ordering might not be the one induced by the coefficients, 
%due to the presence of constants.
%
%More precisely, let us consider the CLIM of non-negative reals and
%the polynomials $2x \, \hat{+} \, 1$ and $x \, \hat{+} \, 6$
%and let us assume $D = \{1, 2, 3\}$.
%The composition of such constraints is actually given just by coefficient 
%addition, so that
%$(2x \, \hat{+} \, 1) \monop (x \, \hat{+} \, 6) = 
%(3x \, \hat{+} \, 7)$.
%However, note that $2x \, \hat{+} \, 1 \leq x \, \hat{+} \, 6$.
%
%
%Similarly for residuation, which is just bounded subtraction of coefficients.
%Since $2x \, \hat{+} \, 1 \leq x \, \hat{+} \, 6$,
%by construction ($2x \, \hat{+} \, 1) \odiv (x \, \hat{+} \, 6)$ is the bottom constraint,
%mapping all variables to $0$.
%Instead, $(x \, \hat{+} \, 6) \odiv (2x \, \hat{+} 1)$ could be described as $\hat{-}x \, \hat{+} \, 5$,
%even if
%the latter falls outside of the polynomials we considered since it has a negative coefficient:
%it suffices to assume that if the actual result of the evaluation of the polynomial is negative 
%then it is put to $0$.
%
%%
%If $D$ is not the singleton, the support of a polynomial is precisely the set of variables occurring in it.
%\end{example}

%The ReSL of constraints also enjoys the cylindric properties, as shown by
%the result below (for cylindric operators and diagonals in the idempotent case, see~\cite{scc}).

\begin{lemma}[Cylindric and polyadic operators for (soft) constraints]
	The ReSL of constraints $\mathbb{C}$ admits cylindric and polyadic operators, defined as
	\begin{itemize}
		\item  $(\exists_x c) \eta = \bigvee \{c \rho \mid \eta\mid_{V \setminus \{x\}} = 
		\rho\mid_{V \setminus \{x\}}\}$ for all $c \in {\mathcal C}, x \in V$
		%\item if $\sigma$ is an injective substitution, then $(s_{\sigma}c)\eta = c(\sigma \circ \eta)$ 
		%for all $c \in \mathcal{C}$
		\item  $(s_\sigma c) \eta = c (\eta \circ \sigma)$ for all $c \in {\mathcal C}, \sigma \in F(V)$	
%		\item $\delta_{x,y}\eta = \left\{
%		\begin{array}{rcl} \bot & & \text{if } \eta(x) = \eta(y); \\
%		\top & & \text{otherwise.}
%		\end{array} \right.$ for all $x, y \in V$
	\end{itemize}
\end{lemma}

Hiding means eliminating variables from the support:
$supp(\exists_x c) \subseteq supp({c}) \setminus {x}$.\footnote{The operator
	is called \emph{projection} in the soft framework,
	and $\exists_x c$ is denoted $c\Downarrow_{V\setminus \{x\}}$.}

\begin{proof}
%Let us consider a finite set $X$ and a constraint $c$. Recall that since $supp(c)$ is finite,
%$c$ can be considered as a function $D^k \rightarrow A$ for $k = \# supp(c)$.
%
%Thus $(\exists_X c) \eta$ just boils down to consider the LUB of $\# supp(c) \setminus X$ 
%sets of $k$-tuples, and t
The properties of the pomonoid action (see Definition~\ref{pomo})
are easily shown to hold for both operators. 
%
As for the cylindric laws (see Definition~\ref{cyli}), first note that the set of functions 
$\rho$ such that $\eta\mid_{V \setminus \{x\}} = \rho\mid_{V \setminus \{x\}}$ is actually finite.
Thus, we have that 
\begin{eqnarray*}
(\exists_x (c \otimes \exists_x d)) \eta & = & \bigvee_\rho \{(c \otimes \exists_x d) \rho \mid \eta\mid_{V \setminus \{x\}} = \rho\mid_{V \setminus \{x\}}\}\\
& = & \bigvee_\rho \{c\rho \otimes (\exists_x d) \rho \mid \eta\mid_{V \setminus \{x\}} = \rho\mid_{V \setminus \{x\}}\} \\
& = & \bigvee_\rho \{c\rho \otimes  (\bigvee_\xi \{d \xi \mid \rho\mid_{V \setminus \{x\}} = \xi\mid_{V \setminus \{x\}}\}) \mid \eta\mid_{V \setminus \{x\}} = \rho\mid_{V \setminus \{x\}}\} \\
& = & \bigvee_\rho \{c\rho \mid \eta\mid_{V \setminus \{x\}} = \rho\mid_{V \setminus \{x\}}\} \otimes \bigvee_\xi \{d \xi \mid \eta\mid_{V \setminus \{x\}} = \xi\mid_{V \setminus \{x\}}\} \\
& = & (\exists_x c) \eta \otimes (\exists_x d) \eta
\end{eqnarray*}

% = 
% =\]
%= \]
% =\]
% =
%(\exists_X c) \eta \otimes (\exists_X d) \eta \]
%%\[ (\exists_X d) \rho = \bigvee \{d \xi \mid \rho\mid_{V \setminus X} = \xi\mid_{V \setminus X}\}\]

[da rivedere]
Let us now move to the polyadic laws (see Definition~\ref{def:poly}).We just consider the third item, 
and we assume that $\sigma \mid_{\sigma^c(X)}$ is injective, thus
\begin{eqnarray*}
(\exists_X s_\sigma c) \eta & = &\bigvee_\rho \{(s_\sigma c) \rho \mid \eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}\} = \bigvee_\rho \{c (\rho \circ \sigma) \mid \eta\mid_{V \setminus X} =   \rho\mid_{V \setminus X}\} \\ 
& = & \bigvee_\xi \{c\xi \mid (\eta \circ \sigma)\mid_{V \setminus \sigma^{c}(X)}  =  \xi\mid_{V \setminus \sigma^{c}(X)}\} \\
& = & (\exists_{\sigma^c(X)} c) (\eta \circ \sigma) = (s_\sigma \exists_{\sigma^c(X)} c) \eta
\end{eqnarray*}

%  \bigvee \{c (\rho \circ \sigma) \mid (\eta\circ \sigma)\mid_{V \setminus \sigma^{c}(X)} = (\rho\circ \sigma)\mid_{V \setminus \sigma^{c}(X)}\}=^{*}\]
\noindent
where it always holds that $\eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}$ implies $(\eta\circ \sigma)\mid_{V \setminus \sigma^{c}(X)} = (\rho\circ \sigma)\mid_{V \setminus \sigma^{c}(X)}$,
while since $\sigma \mid_{\sigma^c(X)}$ is injective we have that
a $\xi$ satisfying $(\eta \circ \sigma)\mid_{V \setminus \sigma^{c}(X)} = \xi\mid_{V \setminus \sigma^{c}(X)}$ can be decomposed as $\rho\circ \sigma$
for a $\rho$ such that $\eta\mid_{V \setminus X} = \rho\mid_{V \setminus X}$
(otherwise, it could happen that for some $\{x, y\} \subseteq \sigma^c(X)$ we have that $\sigma(x) =\sigma(y)$ and 
$\xi(x) \neq \xi(y)$).
\qed
\end{proof}

%
%Finally, the diagonal element $\delta_{x,y}$ has support $\{x, y\}$ for 
%$x \neq y$, while the support for $\delta_{x,x}$ is $\emptyset$. 


Note also that the diagonal elements are not guaranteed to be $\monop$-compact,
even if they have finite support, since $\top$ is not necessarily so.
%
To this end, we close the section by adding the simple result below to the soft constraint lore.

\begin{proposition}
	Let $c \in \mathbb{C}$ be a constraint. It is $\monop$-compact if and only if it has finite support and 
	$c\eta$ is $\monop$-compact for all $\eta$.
\end{proposition}


\section{Polyadic Soft CCP: language and reduction/barbed  semantics}\label{sec:detSCCP}
This section introduces our (meta-)language.
We fix a set of variables $V$, ranged over by $x$, $y$, $\ldots$ , and 
an invertible CLIM $\mathbb S = \langle {\mathcal C}, \leq, \otimes\rangle$, which is 
cylindric over $V$ and whose compact elements
are ranged over by $c$, $d$, $\ldots$.

\begin{definition}[Agents]%
The set $\mathcal{A}$ of all agents, %which is
parametric with respect to a set $\mathcal{P}$ of (unary) procedure declarations $p(x)$,
is given by the following grammar
\[ A \Coloneqq \: \: \mathit{\ostop} \mid \textit{\tell}(c)  \mid \textit{\ask}(c) \rightarrow A \mid A \parallel A \mid %\exists_x A \mid %Z \mid \mu_Z A 
p(x) \mid \exists^{\rho}_x A.\]  
\end{definition}

We consider here the extended agent $\exists^{\rho}_x A$, where $\rho$ is meant to represent a local store. More precisely, the extended agent allows to carry some information about the hidden variable $x$ in an incremental way. In the following, we will often write $\exists_x A$ for $\exists^{\monid}_x A$ \\
We denote by $fv(A)$ the set of free variables of an agent, defined in the expected way 
by structural induction, assuming that $fv(\tell(c)) = sv(c)$ and
$fv(\ask(c) \rightarrow A) = sv(c) \cup fv(A)$. We also remark that $fv(\exists_x A) = fv(A) \setminus 
\{x\}$ and $fv(\exists^{\rho}_x A) = (fv(A) \cup sv(\rho)) \setminus \{x\}$.
%
In the following, we restrict our attention to 
procedure declarations $p(x) = A$ such that $fv(A) = \{x\}$.

We now move to consider the reduction semantics of our language.

\begin{definition}[Substitutions]
Let $[^y/_x] \in F(V)$, defined as: 
\[ [^y/_x](w) = 
		\begin{cases} 
			y & \text{if $w = x$} \\
            w & \text{otherwise}
        \end{cases} \].
We define the substitution operator $[^y/_x]: \mathcal{A} \rarrow \mathcal{A}$ on agents as follows: 

\begin{itemize}
	\item $\ostop[^y/_x] = \ostop$
	\item $\tell(c)[^y/_x] = \tell(s_{[^y/_x]}c)$
	\item $p(w)[^y/_x] =  p([^y/_x](w))$
	\item $(\ask(c) \rightarrow A)[^y/_x] = \ask(s_{[^y/_x]}(c)) \rightarrow A[^y/_x]$
	%\item $[^y/_x] (\exists_w A)  = \exists_w ([^y/_x] A) \ \ \text{for $w \not \in \{x, y\}$}$
    \item $(\exists^{\rho}_w A)[^y/_x] = \exists^{(s_{[^y/_x]} \rho)}_w A[^y/_x] \ \
    \text{for $w \not \in \{x, y\}$}$
	\item $(A_1 \parallel A_2)[^y/_x]  = (A_1[^y/_x] \parallel A_2[^y/_x])$
\end{itemize}
\end{definition}

\begin{remark}
In the following, we consider terms to be equivalent up to $\alpha$-conversion, meaning that terms which differ only for hidden variables can be considered equivalent:
\[\exists_x^\rho A = \exists_y^{(s_{[^y/_x]}\rho)} A[^y/_x] \ \ for \ \ y \not \in sv(\rho) \cup fv(A)\]
Note that this holds thanks to the underlying monoid properties, where we have that $\exists_x \sigma = \exists_y s_{[^y/_x]}(\sigma)$ if $y \not \in sv(\sigma)$.
\end{remark}

Thanks to $\alpha$-conversion, we can define substitution for $\exists^{\rho}_x A$ as above, even if the substitution function $[^y/_x]$ is not injective. Other cases can be managed by renaming, since the following holds:

\begin{proposition}
Let $A \in \mathcal{A}$, $x \not \in fv(A)$. Then $A[^y/_x] = A$.
\end{proposition}

\begin{proof}
For $\ostop$, $\tell(c)$, $p(w)$ the statement is trivially true, as we have that
\begin{itemize}
	\item $\ostop[^y/_x] = \ostop$
	\item $\tell(c)[^y/_x] = \tell(s_{[^y/_x]}c) = \tell(c)$ by polyadic laws and $x \not
	\in fv(\tell(c)) = sv(c)$.
	\item $p(w)[^y/_x] = p(w)$ by $sv(p(w)) = {w} \wedge x \not \in sv(p(w)) \implies
	w \not = x$.
\end{itemize}
As for the other agents, the statement can be proved by inductive reasoning, assuming it to be true for subagents in $\ask(c) \rightarrow A$, $(A_1 || A_2)$ and $\exists^{\rho}_w A$. Indeed we obtain:
\begin{itemize}
	\item $(\ask(c) \rightarrow A)[^y/_x] =  
	\ask(s_{[^y/_x]}c) \rightarrow A[^y/_x] = \ask(c) \rightarrow A$
	by hypothesis and polyadic laws.
	\item $(A_1 || A_2)[^y/_x] = (A_1[^y/_x] \parallel A_2[^y/_x])) = (A_1 \parallel A_2)$
	by hypothesis.
\end{itemize}
As for $\exists^{\rho}_w A$, recall that $fv(\exists^{\rho}_w A) = (fv(A) \cup sv(\rho)) \setminus \{w\}$, thus $x \not = w \wedge x \not \in fv(\exists^{\rho}_w A) \implies x \not \in fv(A) \wedge x \not \in sv(\rho)$. Then we have two possible cases:
\begin{itemize}
	\item $w \not = x$. $(\exists^{\rho}_w A)[^y/_x] = \exists^{s_{[^y/_x]}\rho}_w A[^y/_x] = 
	\exists^{\rho}_w A[^y/_x]$ (by $x \not = w$) $= \exists^{\rho}_w A$ (by hypotheses).
	\item $w = x$. $(\exists^{\rho}_x A)[^y/_x] = ((\exists^{\rho}_x A)[^z/_x])[^y/_x] \ \ 
	\text{for $z$ fresh}$ (by $\alpha$-conversion) $= (\exists^{\rho}_z A)[^y/_x] = \exists^{\rho}_z A$
	(by the reasoning above) $= \exists^{\rho}_x A$ (again by $\alpha$-conversion).   
\end{itemize}
\end{proof}

\begin{definition}[Reductions]\label{def:reductions}
Let $\Gamma = {\mathcal A} \times \C$ be the set of \emph{configurations}.
The \emph{direct reduction semantics} for SCCP is the pair 
$\langle \Gamma,  \mapsto \rangle$
such that $\mapsto \, \, \subseteq \, \,\Gamma \times   \Gamma$ is the family 
 of binary relations indexed over sets of variables,
%$2^V$,
%between them, 
i.e., $\mapsto = \bigcup_{\Delta \subseteq V} \mapsto_\Delta$ and 
$\mapsto_\Delta \, \, \subseteq \, \,\Gamma \times \Gamma$, obtained by the rules in 
Table~\ref{fig:operational}.

The \emph{reduction semantics} for SCCP is the pair 
$\langle \Gamma,  \rightarrow \rangle$
such that $\rightarrow \, \, \subseteq \, \,\Gamma \times   \Gamma$ is the family 
 of binary relations indexed over sets of variables,
%$2^V$,
%between them, 
i.e., $\rightarrow = \bigcup_{\Delta \subseteq V} \rarrow_\Delta$ and 
$\rarrow_\Delta \, \, \subseteq \, \,\Gamma \times \Gamma$, obtained by the rules in 
Table~\ref{fig:operational} and Table~\ref{fig:operational2}.
\end{definition}

%\vspace{-.25cm}
\def\odiv{\; {\ominus\hspace{-6pt} \div} \;}
\def\odivvv{\; {\ominus\hspace{-6pt} \div} \;}

\begin{table}  %\hfil5
  %\scalebox{0.9}{
   \begin{center}
   \begin{tabular}{llll} 
   %
   \mbox{\bf A1}& $ {\displaystyle \langle \hbox{\tell}(c), \sigma \rangle \mapsto  \langle 
   \hbox{\ostop}, \sigma \otimes c\rangle}$
   \ \ \ & \bf{Tell}&
  \\ 
  &\mbox{   }&\mbox{   } &\mbox{   }
  \\
  \mbox{\bf A2}& $\frac {\displaystyle sv(\sigma) \cup sv(c) \cup fv(A) \subseteq \Delta \wedge \sigma \leq c}{\displaystyle
  	\begin{array}{l} \langle \hbox{\ask}(c) \rightarrow A, \sigma \rangle \mapsto_\Delta \langle A, \sigma \rangle   	\end{array}}$
    \ \ \ & \bf{Ask}&
    \\
    &\mbox{   }&\mbox{   }&
    \\
  \mbox{\bf A3}& $\frac {\displaystyle sv(\sigma) \cup \{y\} \subseteq \Delta \wedge \displaystyle p(x) = A \in \mathcal{P} }
  {\displaystyle\langle p(y),\sigma\rangle \mapsto_\Delta \langle A[^y/_x], \sigma \rangle}$ 
  &\bf{Rec}&
  \\
    &\mbox{   }&\mbox{   }&
    %\\
    %&\mbox{   }&\mbox{   }&
    %\\
    %\mbox{\bf A4}& $\frac {\displaystyle sv(\sigma) \cup fv(\exists_x A) \subseteq 
    %\Delta \wedge w \not \in \Delta }
    %{\displaystyle\langle \exists_x A,\sigma\rangle \mapsto_\Delta \langle [^w/_x]A,
    %\sigma\rangle}$
    %&\bf{Hide}&
    %\\
   %&\mbox{   }&\mbox{   }&
  \\
    \mbox{\bf A4}& $\frac {\displaystyle \langle A, \rho \otimes \sigma_0 \rangle
    \mapsto \langle B, \sigma_1 \rangle \wedge x \not \in sv(\sigma) \wedge \sigma_0 
    = \sigma \odiv \exists_x \rho }
    {\displaystyle\langle \exists^{\rho}_x A,\sigma\rangle \mapsto_\Delta \langle 
    \exists^{\sigma_1 \odiv \sigma_0}_x B, \sigma_0 \otimes \exists_x(\sigma_1 \odiv \sigma_0) 
    \rangle}$
    &\bf{Hide}&
  \end{tabular}
  \end{center}
\caption{Axioms of the reduction semantics for SCCP.}
\label{fig:operational}
\end{table}

\begin{table}  %\hfil5
  %\scalebox{0.9}{
   \begin{center}
   \begin{tabular}{llll} 
   %
  \mbox{\bf R1}& $\frac {\displaystyle \langle A,\sigma \rangle \rightarrow_\Delta \langle A', \sigma' \rangle
  \wedge fv(B) \subseteq \Delta} 
  {\displaystyle \begin{array}{l}
                          \langle A\parallel B, \sigma \rangle \rightarrow_\Delta \langle A'\parallel B, \sigma' \rangle
                          \end{array}}$ 
    & \bf{Par1}&
  \\
  & \mbox{   }&\mbox{   }&
  \\
    \mbox{\bf R2}& $\frac {\displaystyle \langle A,\sigma \rangle \rightarrow_\Delta \langle A', \sigma'   \rangle
    	\wedge fv(B) \subseteq \Delta} 
    {\displaystyle 
    	\begin{array}{l} \langle B\parallel A, \sigma \rangle \rightarrow_\Delta \langle B\parallel A', \sigma' \rangle
    	\end{array}}$& \bf{Par2}&
  \end{tabular}
  \end{center}
\caption{Contextual rules of the reduction semantics for SCCP.}
\label{fig:operational2}
\end{table}

The split distinguishes between axioms and rules guaranteeing the closure with respect to the parallel operator. Indeed, rules {\bf  R1}  and {\bf  R2} model the interleaving of two agents in parallel.
%
%
In {\bf A1} a constraint $c$ is added to the store $\sigma$.
%, which in the next step will be $\sigma \otimes c$.
%
{\bf A2} checks if $c$ is entailed by  $\sigma$: if not, the computation is blocked.

Axiom {\bf A3} replaces a procedure identifier with the associated body, renaming the formal parameter with the actual one:
%$A[^y/_x]$ stands for the agent obtained by replacing all the occurrences of $x$ with $y$.
%
%Axiom {\bf A4} hides the variable $x$ occurring in $A$, replacing it  
%with a globally fresh variable,
%as ensured by $w \not \in \Delta$.
%The latter is more general than just requiring that 
%$w \not \in fv(\exists_x A) \cup sv(\sigma)$, since
%$\langle B, \rho \rangle   \rarrow_\Delta$ implies that 
%$fv(B) \cup sv(\rho) \subseteq \Delta$.\footnote{Our rule is  reminiscent of 
%$(8)$ in~\cite[p.~342]{popl91}.}

In axiom {\bf A4} we consider instead local variables, where the hiding operator carries some information on the variables it abstracts.
More precisely, according to~\cite{extendedHiding} we consider an extended operator $\exists_x^\rho$, for $\rho$ the local store.
Thanks again to the residuation operator, the rule for the extended hidings can be defined as {\bf Hide-local}. The precondition states that $x \not \in sv(\sigma)$: this ensures that $\sigma_0$ does not contain free occurences of $x$, as it is obtained by removing $\exists_x \rho$ from $\sigma$. The intuition is then that $x$ can only appear in the local store $\rho$, and then in $\sigma_1$. Thus, hiding $x$ means to remove it from the resulting store, by letting it $\sigma_0 \otimes \exists_x(\sigma_1 \odiv \sigma_0)$. On the other hand, the local information carried by the hide operator is updated to $\sigma_1 \odiv \sigma_0$, which can still contain $x$. \\
\smallskip

Let $\gamma = \langle A, \sigma \rangle$ be a configuration.
%
We denote by $fv(\gamma)$ the set $fv(A) \cup sv(\sigma)$ and by
$\gamma[^z/_w]$ the component-wise application of substitution $[^z/_w]$.

\begin{lemma}[On monotonicity]
\label{mono}
Let $\langle A, \sigma \rangle \rightarrow_\Delta \langle B, \sigma' \rangle$ be a reduction. 
Then
\begin{enumerate}
\item $sv(\sigma') \subseteq sv(\sigma)\cup fv(A) \subseteq \Delta$;
\item $\sigma \leq \sigma'$;
\item $\langle A, \sigma \rangle \rightarrow_{\Delta'} \langle B, \sigma' \rangle$
         for all $\Delta'. sv(\sigma)\cup fv(A) \subseteq \Delta' \wedge fv(B) \cap \Delta' \subseteq fv(A)$;
\item $\langle A, \sigma \otimes \rho \rangle \rightarrow_\Delta \langle B, \sigma' \otimes \rho \rangle$
         for all $\rho \in  \C^\otimes. sv(\rho) \subseteq \Delta$. 
\end{enumerate}
 \end{lemma}
 
 All statements are straightforward. 

As for item 1, by construction $sv(\sigma)\cup fv(A) \subseteq \Delta$: since 
only rule {\bf A1} can modify the store
and $sv(\sigma \otimes c) \subseteq sv(\sigma) \cup sv(c)$, then the statement holds.
Similarly for item 2, since $\sigma \leq \sigma \otimes c$.
Item 3 is again true by construction. 
As for item 4, it suffices to also note that 
$\sigma, \rho \in  \C^\otimes$ ensure that $\sigma \otimes \rho \in  \C^\otimes$
and clearly {\bf A2} will still be executable. 

\begin{definition}[Increasing computations]\label{def:min}
Let $\gamma_0  \rightarrow_{\Delta_1} \gamma_1  \rightarrow_{\Delta_2} \gamma_2 \rightarrow_{\Delta_3} \dots$ be a
(possibly infinite) computation. 
%\marginpar{added ``infinite'' before computation}
It is increasing if $\Delta_k \subseteq \Delta_{k+1}$ for any $k >1$, and
it is minimally increasing if $\Delta_k + fn(\gamma_k) = \Delta_{k+1}$ for any $k>1$.
\end{definition}

What is noteworthy is that in such computation the sets $\Delta$'s are always uniquely identified,
once $\Delta_1$ is fixed.
Thanks to Lemma \ref{mono}, for the sake of simplicity and without loss of generality 
in the following we restrict our attention to minimally increasing computations, dropping
altogether the subscripts $\Delta$'s whenever they are irrelevant.


\section{Saturated Bisimulation}\label{sec:saturated}
As proposed in \cite{pippo} for crisp languages, we define a barbed equivalence between two agents~\cite{barbed}.  
%
Intuitively, barbs are basic observations (predicates) on the states of a system, and in our case they correspond 
to the compact constraints in $\mathcal{C}^\otimes$.

\begin{definition} [Barbs]
Let $\langle A, \sigma \rangle$ be a configuration and $c \in \mathcal{C}^\otimes$
and we say that $\langle A, \sigma \rangle$ verifies $c$, or that $\langle A, \sigma \rangle \downarrow_c$ holds, if  $c \leq \sigma$.
\end{definition}

However, since \emph{barbed bisimilarity} is an equivalence already for CCP, along~\cite{pippo}
we propose the use of \emph{saturated bisimilarity}
%~\cite{barbedMontanari} has been proposed 
in order to obtain a congruence:
%
Definition~\ref{def:strongsb} and Definition~\ref{def:weaksb} respectively provide the strong and weak definition of saturated bisimilarity.
%We say that $\gamma = \langle P, \sigma\rangle$ satisfies the barb $c$, written $\gamma \downarrow_c$,
%iff $\gamma \longrightarrow \gamma'$ and $\gamma' \downarrow_c$.
%\marginpar{Are barbs compact?}

\begin{definition}[Saturated bisimilarity]\label{def:strongsb} A saturated bisimulation is a symmetric relation $R$ on configurations such that whenever
%$(\gamma_1,\gamma_2) \in R$ with $\gamma_1 = \langle A, \sigma \rangle$
%and $\gamma_2 = \langle B, \rho \rangle$
$( \langle A, \sigma \rangle,\langle B, \rho \rangle) \in R$
\begin{enumerate}
\item if $\langle A, \sigma \rangle \downarrow_c$ then $\langle B, \rho \rangle \downarrow_c$;
\item if $\langle A, \sigma \rangle \longrightarrow \gamma'_1$ then there is $\gamma'_2$ such that $\langle B, \rho \rangle \longrightarrow \gamma'_2$ and $(\gamma'_1, \gamma'_2) \in R$;
\item $(\langle A,\sigma \otimes d\rangle, \langle B,\rho \otimes d \rangle) \in R$ for  all $d \in \mathcal{C}^\otimes$.
\end{enumerate}
We say that $\gamma_1$ and $\gamma_2$ are  saturated bisimilar ($\gamma_1  \sim_{\mathit{s}} \gamma_2$) if there exists a  saturated  bisimulation $R$ such that $(\gamma_1 , \gamma_2 ) \in R$. We write $A \sim_{\mathit{s}} B$ if $\langle A, \bot\rangle \sim_{\mathit{s}} \langle B, \bot \rangle$.
\end{definition}

We now let $\longrightarrow^*$ denote the reflexive and transitive closure of $\longrightarrow$, restricted to increasing computations.

\begin{definition} [Weak barbs]
Let $\langle A, \sigma \rangle$ be a configuration and $c \in \mathcal{C}^\otimes$.
We say that $\langle A, \sigma \rangle$ weakly verifies $c$, or that $\langle A, \sigma \rangle \Downarrow_c$ holds, 
if  there exists $\gamma' = \langle B, \rho \rangle$ such that 
$\gamma \longrightarrow^* \gamma'$ and $c \leq \exists_{X} \rho$ for $X = fv(\gamma') \setminus fv(\gamma)$.
\end{definition}

\begin{definition}[Weak saturated bisimilarity]\label{def:weaksb} A weak saturated bisimulation is a symmetric relation $R$ on configurations such that whenever
%$(\gamma_1,\gamma_2) \in R$ with $\gamma_1 = \langle A, \sigma \rangle$
%and $\gamma_2 = \langle B, \rho \rangle$
$( \langle A, \sigma \rangle,\langle B, \rho \rangle) \in R$
\begin{enumerate}
\item if $\langle A, \sigma \rangle \downarrow_c$ then $\langle B, \rho \rangle \Downarrow_c$;
\item if $\langle A, \sigma \rangle \longrightarrow \gamma'_1$ then there is $\gamma'_2$ such that $\langle B, \rho \rangle \longrightarrow^* \gamma'_2$ and $(\gamma'_1, \gamma'_2) \in R$;
\item $(\langle A,\sigma \otimes d\rangle, \langle B,\rho \otimes d \rangle) \in R$ for  all $d \in \mathcal{C}^\otimes$.
\end{enumerate}
We say that $\gamma_1$ and $\gamma_2$ are  weakly saturated bisimilar ($\gamma_1  \approx_{\mathit{s}} \gamma_2$) if there exists a  
weak saturated  bisimulation $R$ such that $(\gamma_1 , \gamma_2 ) \in R$. 
We write $A \approx_{\mathit{s}} B$ if $\langle A, \bot\rangle \approx_{\mathit{s}} \langle B, \bot \rangle$.
\end{definition}

The asymmetry is functional to later sections. However, it is clearly equivalent to the standard symmetric version.

\begin{definition}[Weak saturated bisimilarity, 2]\label{def:weaksb2}
Weak saturated bisimilarity coincides with the relation 
obtained from Definition~\ref{def:strongsb} by replacing $\longrightarrow$ with $\longrightarrow^*$ and $\downarrow_c$ with $\Downarrow_c$.
\end{definition}

Since $\sim_{\mathit{s}}$ (and $\approx_{\mathit{s}}$) is a saturated bisimulation, it is clearly upward closed and it is also a congruence: indeed, a context can modify the behaviour of a configuration only by adding constraints to its store.
%\marginpar{to be proved for $\exists_x-$ (not needed for Prop.3)}

\medskip
We now show that $\approx_{\mathit{s}}$, as given in Definition~\ref{def:weaksb}, coincides with the observational equivalence $\sim_o$ (see Definition~\ref{def:obequivalence}). First we recall the notion of and a classic result on \emph{cofinality}: two (possibly infinite) chains $c_0 \leq c_1 \leq \dots$ and  $d_0 \leq d_1 \leq \dots$ are said to be \emph{cofinal} if for all $c_i$ there exists a $d_j$ such that $c_i \leq d_j$ and, vice-versa, for all $d_i$ there exists a $c_j$ such that $d_i \leq c_j$.

\begin{lemma}\label{lem:cofinality} 
Let $c_0 \leq c_1 \leq \dots$ and $d_0 \leq d_1 \leq \dots $ be two chains. \emph{(1)} If they are cofinal, then they have the same limit, i.e., $\bigvee_i c_i = \bigvee_i d_i$. \emph{(2)} If the elements of the chains are $\otimes$-compact and $\bigvee_i c_i = \bigvee_i d_i$, then the two chains are cofinal.\end{lemma}
%\marginpar{questo richiede che tell inserisca solo compatti}



To prove Theorem~\ref{prop:weaksbequivobs}, besides cofinality from Lemma~\ref{lem:cofinality} we need to relate weak barbs and fair computations.

\begin{lemma}\label{lem:barbsfair}
Let $\xi = \gamma_0 \longrightarrow \gamma_1 \longrightarrow \ldots$ be a (possibly infinite) fair computation. If $\gamma_0 \Downarrow_d$ then there exists a store $\sigma_i$ in $\xi$ such that $d \leq \exists_{X_i} \sigma_i$ for $X_i = fv(\gamma_i) \setminus fv(\gamma_0)$.
\end{lemma}

The lemma is a direct consequence of confluence (see Theorem~\ref{prop:confluence}).

\begin{theorem}\label{prop:weaksbequivobs}
Let $A$, $B$ be agents. Then $A \sim_o B$ if and only if $A \approx_{\mathit{s}} B$.
\end{theorem}
%\marginpar{L'unica cosa da provare \`e in realt\`a il Lemma 1}



\section{Semantics equivalence}

\section{Concluding Remarks}\label{sec:conclusion}

\bibliographystyle{splncs03}%splncs
\bibliography{main,softccp}

\end{document}
